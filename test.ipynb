{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载数据\n",
    "data = pd.read_csv('Task2.csv')\n",
    "\n",
    "# 数据结构\n",
    "# iSub: 被试编号\n",
    "# iTrial: 试次编号\n",
    "# feature1, feature2, feature3, feature4: 四个特征\n",
    "# choice: 被试的类别选择 (0或1)\n",
    "# feedback: 反馈 (0: 错误, 1: 正确)\n",
    "\n",
    "# 提取特征和其他变量\n",
    "features = data[['feature1', 'feature2', 'feature3', 'feature4']].values\n",
    "choices = data['choice'].values\n",
    "feedback = data['feedback'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义贝叶斯模型\n",
    "with pm.Model() as model:\n",
    "    # 信念参数: k 分割方法\n",
    "    k = pm.DiscreteUniform('k', lower=1, upper=4)\n",
    "    \n",
    "    # 模糊性参数 beta\n",
    "    beta = pm.HalfNormal('beta', sigma=1)\n",
    "    \n",
    "    # 定义刺激的中心点 (简化定义为固定的四个类别中心)\n",
    "    # 假设类别C1在(0.25, 0.25, 0.25, 0.25), 类别C2在(0.75, 0.75, 0.75, 0.75)\n",
    "    center_C1 = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "    center_C2 = np.array([0.75, 0.75, 0.75, 0.75])\n",
    "    \n",
    "    # 计算距离\n",
    "    d_C1 = tt.sqrt(tt.sum(tt.square(features - center_C1), axis=1))\n",
    "    d_C2 = tt.sqrt(tt.sum(tt.square(features - center_C2), axis=1))\n",
    "    \n",
    "    # 计算选择类别C1的概率 (软分类器)\n",
    "    p_C1 = tt.nnet.softmax(tt.stack([-beta * d_C1, -beta * d_C2], axis=1))[:, 0]\n",
    "    \n",
    "    # 概率分布（类别选择）\n",
    "    choice_likelihood = pm.Bernoulli('choice', p=p_C1, observed=choices)\n",
    "    \n",
    "    # 3. 似然函数：反馈与正确选择之间的一致性\n",
    "    # 假设反馈是确定的，即选择正确类别会得到反馈1，选择错误类别会得到反馈0\n",
    "    correct_choice = (choices == feedback).astype(int)\n",
    "    feedback_likelihood = pm.Bernoulli('feedback', p=p_C1, observed=correct_choice)\n",
    "    \n",
    "    # 4. 采样后验分布\n",
    "    trace = pm.sample(1000, tune=1000, cores=2, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "def fit_bayesian_model(df):\n",
    "    # 获取条件\n",
    "    conditions = df['condition'].unique()\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        # 先验分布\n",
    "        beta = pm.Uniform('beta', lower=0, upper=10)\n",
    "\n",
    "        # 类别中心点\n",
    "        centers = pm.Normal('centers', mu=0, sigma=1, shape=(4, 4))  # 4个类别，每个类别4个特征\n",
    "\n",
    "        # 观察数据\n",
    "        for i, row in df.iterrows():\n",
    "            stimulus = row['stimulus']\n",
    "            true_category = row['true_category']\n",
    "            chosen_category = row['chosen_category']\n",
    "            feedback = row['feedback']\n",
    "            \n",
    "            # 计算距离\n",
    "            distances = pm.math.sqrt(pm.math.sum((centers - stimulus)**2, axis=1))\n",
    "            probabilities = pm.math.exp(-beta * distances) / pm.math.sum(pm.math.exp(-beta * distances))\n",
    "\n",
    "            # 选择类别的概率\n",
    "            chosen_prob = probabilities[chosen_category]\n",
    "            feedback_prob = pm.Bernoulli('feedback_{}'.format(i), p=chosen_prob, observed=feedback)\n",
    "\n",
    "        # 后验采样\n",
    "        trace = pm.sample(2000, tune=1000)\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "class CategoryLearningModel:\n",
    "    def __init__(self, K=4, beta=1.0):\n",
    "        self.K = K  # Number of partition methods\n",
    "        self.beta = beta  # Softness of partition\n",
    "        self.theta = self.initialize_theta()\n",
    "        \n",
    "    def initialize_theta(self):\n",
    "        # Initialize theta with uniform distribution over partitions and beta\n",
    "        k = np.random.choice(self.K)\n",
    "        beta = np.random.uniform(0.1, 10.0)  # Initialize beta between 0.1 and 10\n",
    "        return {'k': k, 'beta': beta}\n",
    "    \n",
    "    def distance_to_centroid(self, x, centroid):\n",
    "        return np.linalg.norm(x - centroid)\n",
    "    \n",
    "    def compute_probabilities(self, x):\n",
    "        # Compute the probability of x belonging to each category\n",
    "        k = self.theta['k']\n",
    "        beta = self.theta['beta']\n",
    "        \n",
    "        # Define centroids for the 4 partition methods\n",
    "        centroids = [\n",
    "            np.array([0.5, 0.5, 0.5, 0.5]),\n",
    "            np.array([0.5, 0.5, 0.5, 0.5]),\n",
    "            np.array([0.5, 0.5, 0.5, 0.5]),\n",
    "            np.array([0.5, 0.5, 0.5, 0.5])\n",
    "        ]\n",
    "        \n",
    "        distances = [self.distance_to_centroid(x, centroids[i]) for i in range(4)]\n",
    "        exp_neg_beta_distances = np.exp(-beta * np.array(distances))\n",
    "        probabilities = exp_neg_beta_distances / np.sum(exp_neg_beta_distances)\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def likelihood(self, x, c, r):\n",
    "        probabilities = self.compute_probabilities(x)\n",
    "        p_c_given_x = probabilities[c]\n",
    "        \n",
    "        if r == 1:\n",
    "            p_r_given_c_x = 1.0\n",
    "        else:\n",
    "            p_r_given_c_x = 0.0\n",
    "        \n",
    "        return p_c_given_x * p_r_given_c_x\n",
    "    \n",
    "    def update_theta(self, x, c, r):\n",
    "        # Example calculation for posterior\n",
    "        posterior = np.random.rand(self.K)  # Replace with actual calculation\n",
    "        posterior /= np.sum(posterior)  # Normalize to make it a probability distribution\n",
    "        \n",
    "        # Make sure posterior is an array with correct shape\n",
    "        if posterior.ndim != 1 or len(posterior) != self.K:\n",
    "            raise ValueError(\"Posterior must be a 1D array with length equal to K.\")\n",
    "        \n",
    "        self.theta['k'] = np.random.choice(self.K, p=posterior)\n",
    "        self.theta['beta'] = np.random.uniform(0.1, 10.0)\n",
    "        \n",
    "    def choose_category(self, x):\n",
    "        probabilities = self.compute_probabilities(x)\n",
    "        return np.argmax(probabilities)\n",
    "    \n",
    "    def fit(self, X, y, feedback):\n",
    "        for x, c, r in zip(X, y, feedback):\n",
    "            self.update_theta(x, c, r)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [self.choose_category(x) for x in X]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model = CategoryLearningModel()\n",
    "    \n",
    "    # Generate some random data for demonstration\n",
    "    X = np.random.rand(10, 4)  # 10 samples, 4 features each\n",
    "    y = np.random.randint(0, 2, 10)  # Random categories (0 or 1)\n",
    "    feedback = np.random.randint(0, 2, 10)  # Random feedback (0 or 1)\n",
    "    \n",
    "    model.fit(X, y, feedback)\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
