{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取项目根目录\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# 导入预处理器\n",
    "import importlib\n",
    "import src.preprocess as preprocess\n",
    "importlib.reload(preprocess)\n",
    "from src.preprocess import Preprocessor_A, Preprocessor_B\n",
    "\n",
    "# 初始化预处理器\n",
    "preprocessor_a = Preprocessor_A()\n",
    "preprocessor_b = Preprocessor_B()\n",
    "\n",
    "# 导入配置数据\n",
    "from config import body_length, features_range, canvas_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task1a, Task1b, Task3c preprocess\n",
    "def preprocess_main_a(project_root, taskID, subIDs, features_range, canvas_settings, body_length, preprocessor):\n",
    "    input_path = Path(project_root) / 'data' / 'raw' / taskID\n",
    "    output_path = Path(project_root) / 'data' / 'processed' / taskID \n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for subID in subIDs:\n",
    "        if taskID == 'Task1a':\n",
    "            feature_init = pd.DataFrame({\n",
    "            'neck_length': [0.5], 'head_length': [0.5], 'leg_length': [0.5], 'tail_length': [0.5],\n",
    "            'neck_angle': [0.5], 'head_angle': [0.5], 'leg_angle': [0.5], 'tail_angle': [0.5]\n",
    "         })\n",
    "        elif taskID == 'Task1b':\n",
    "            stimulus_data = pd.read_csv(input_path / f'{taskID}_{subID}_sti.csv')\n",
    "            feature_init = stimulus_data[stimulus_data['type'] == 2]\n",
    "        else:\n",
    "            feature_init = pd.read_csv(input_path / f'{taskID}_{subID}_sti.csv')\n",
    "            \n",
    "        mouse_trajactory = pd.read_csv(input_path / f'{taskID}_{subID}_mouse.csv')\n",
    "        \n",
    "        feature_trajactory = preprocessor.process(taskID, feature_init, mouse_trajactory, features_range, canvas_settings, body_length)\n",
    "        feature_trajactory.to_csv(os.path.join(output_path, f'{taskID}_{subID}_feature.csv'), index=False)\n",
    "\n",
    "# Task2, Task3a, Task3b preprocess\n",
    "def preprocess_main_b(project_root, taskID, subIDs, preprocessor):\n",
    "    input_path = Path(project_root) / 'data' / 'raw' / taskID\n",
    "    output_path = Path(project_root) / 'data' / 'processed'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    all_data = []\n",
    "    for subID in subIDs:\n",
    "        if taskID in ['Task2', 'Task3a']:\n",
    "            stimulus_data = pd.read_csv(input_path / f'{taskID}_{subID}_sti.csv')\n",
    "        elif taskID == 'Task3b':\n",
    "            left_stimulus_data = pd.read_csv(input_path / f'{taskID}_{subID}_left.csv')\n",
    "            right_stimulus_data = pd.read_csv(input_path / f'{taskID}_{subID}_right.csv')\n",
    "            stimulus_data = pd.merge(left_stimulus_data, right_stimulus_data, on=['pairID'])\n",
    "\n",
    "        behavior_data = pd.read_csv(input_path / f'{taskID}_{subID}_bhv.csv')\n",
    "\n",
    "        combined_data = preprocessor.process(taskID, stimulus_data, behavior_data)\n",
    "        combined_data.insert(0, 'iSub', subID)\n",
    "        all_data.append(combined_data)\n",
    "\n",
    "    processed_data = pd.concat(all_data, ignore_index=True)\n",
    "    processed_data.to_csv(os.path.join(output_path, f'{taskID}_processed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task1b, Task3c reconstruct\n",
    "def preprocess_construct(project_root, taskID, subIDs):\n",
    "    raw_path = Path(project_root) / 'data' / 'raw' / taskID\n",
    "    processed_path = Path(project_root) / 'data' / 'processed' / taskID\n",
    "    output_path = Path(project_root) / 'data' / 'processed'\n",
    "\n",
    "    all_data = []\n",
    "    for subID in subIDs:\n",
    "        if taskID == 'Task1b':\n",
    "            stimulus_data = pd.read_csv(raw_path / f'{taskID}_{subID}_sti.csv')\n",
    "            stimulus_data = stimulus_data.drop(columns=['version', 'display_height', 'PairID'])\n",
    "            stimulus_data['type'] = stimulus_data['type'].replace({1: 'target', 2: 'adjust_init'})\n",
    "\n",
    "        elif taskID == 'Task3c':\n",
    "            stimulus_data = pd.read_csv(raw_path / f'{taskID}_{subID}_sti.csv')\n",
    "            stimulus_data.insert(0, 'type', 'adjust_init')\n",
    "\n",
    "        feature_trajactory = pd.read_csv(processed_path / f'{taskID}_{subID}_feature.csv')\n",
    "        adjust_after = feature_trajactory.groupby('iTrial').last().reset_index()\n",
    "\n",
    "        new_rows = stimulus_data[stimulus_data['type'] == 'adjust_init'][['iTrial', 'body_ori']].copy()\n",
    "        new_rows.insert(0, 'type', 'adjust_after')\n",
    "\n",
    "        feature_columns = ['neck_length', 'head_length', 'leg_length', 'tail_length', \n",
    "                        'neck_angle', 'head_angle', 'leg_angle', 'tail_angle']\n",
    "        new_rows = new_rows.merge(adjust_after[['iTrial'] + feature_columns], on='iTrial', how='left')\n",
    "\n",
    "        combined_data = pd.concat([stimulus_data, new_rows], ignore_index=True)\n",
    "        combined_data.insert(0, 'iSub', subID)\n",
    "        all_data.append(combined_data)\n",
    "\n",
    "    processed_data = pd.concat(all_data, ignore_index=True)\n",
    "    processed_data.to_csv(os.path.join(output_path, f'{taskID}_processed.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subIDs = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
    "# preprocess_main_a(project_root, 'Task1a', subIDs, features_range, canvas_settings, body_length, preprocessor_a)\n",
    "# preprocess_main_a(project_root, 'Task1b', subIDs, features_range, canvas_settings, body_length, preprocessor_a)\n",
    "# preprocess_main_a(project_root, 'Task3c', subIDs, features_range, canvas_settings, body_length, preprocessor_a)\n",
    "\n",
    "# preprocess_construct(project_root, 'Task1b', subIDs)\n",
    "# preprocess_construct(project_root, 'Task3c', subIDs)\n",
    "\n",
    "preprocess_main_b(project_root, 'Task2', subIDs, preprocessor_b)\n",
    "# preprocess_main_b(project_root, 'Task3a', subIDs, preprocessor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptive Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取项目根目录\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# 导入处理器\n",
    "import importlib\n",
    "import src.error_evaluation as error_evaluation\n",
    "importlib.reload(error_evaluation)\n",
    "from src.error_evaluation import Processor\n",
    "\n",
    "# 初始化预处理器\n",
    "processor = Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path(project_root) / 'data' / 'processed'\n",
    "processed_data = pd.read_csv(processed_path / f'Task1b_processed.csv')\n",
    "\n",
    "error = processor.error_calculation(processed_data)\n",
    "summary = processor.error_summary(error)\n",
    "\n",
    "# 保存结果\n",
    "result_path = Path(project_root) / 'results' / 'Raw'\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "# 使用示例：\n",
    "processor.plot_error(error, \"length\")  # 绘制长度误差图\n",
    "processor.plot_error(error, \"angle\")   # 绘制角度误差图\n",
    "# 使用函数\n",
    "processor.plot_error_by_feature(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recording Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取项目根目录\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# # 导入处理器\n",
    "# import importlib\n",
    "# import src.audio_coding as audio_coding\n",
    "# importlib.reload(audio_coding)\n",
    "# from src.audio_coding import Processor\n",
    "\n",
    "# # 初始化预处理器\n",
    "# processor = Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define body parts and their corresponding column names\n",
    "BODY_PARTS = {\n",
    "    '脖子': 'neck_value',\n",
    "    '头': 'head_value',\n",
    "    '腿': 'leg_value',\n",
    "    '尾巴': 'tail_value'\n",
    "}\n",
    "\n",
    "# Define description keywords and their corresponding values\n",
    "DESCRIPTIONS = {\n",
    "    '长': 3,\n",
    "    '短': 1,\n",
    "    '中等': 2,\n",
    "    '适中': 2\n",
    "}\n",
    "\n",
    "# Define possible modifiers between body parts and descriptions in \"比\" pattern\n",
    "MODIFIERS = ['比较', '很', '等']\n",
    "\n",
    "def extract_values(text):\n",
    "    # Initialize the result dictionary with None\n",
    "    result = {\n",
    "        'invalid': 0,\n",
    "        'noinfo': 0,\n",
    "        'neck_value': None,\n",
    "        'head_value': None,\n",
    "        'leg_value': None,\n",
    "        'tail_value': None\n",
    "    }\n",
    "    \n",
    "    # Check if text is NaN or empty after stripping\n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        result['invalid'] = 1\n",
    "        return result\n",
    "    \n",
    "    # Split the text by Chinese comma and remove any trailing punctuation\n",
    "    items = re.split(r'[，,]', text)\n",
    "    \n",
    "    for item in items:\n",
    "        item = item.strip('。.？?！!、')\n",
    "        if not item:\n",
    "            continue\n",
    "        \n",
    "        # Check if there's a comparison with \"比\" (but not \"比较\")\n",
    "        has_comparison = \"比\" in item and \"比较\" not in item\n",
    "        \n",
    "        # Find all body parts mentioned in the item\n",
    "        mentioned_parts = [part for part in BODY_PARTS.keys() if part in item]\n",
    "        \n",
    "        if not mentioned_parts:\n",
    "            continue\n",
    "            \n",
    "        # Find description keywords, but ensure \"长\" is not part of another word\n",
    "        descriptions_found = []\n",
    "        for desc in DESCRIPTIONS.keys():\n",
    "            if desc == '长':\n",
    "                # Check if '长' exists but not as part of '长度'\n",
    "                if '长' in item and '长度' not in item:\n",
    "                    descriptions_found.append(desc)\n",
    "            else:\n",
    "                if desc in item:\n",
    "                    descriptions_found.append(desc)\n",
    "        \n",
    "        if len(descriptions_found) >= 1:\n",
    "            desc_value = DESCRIPTIONS[descriptions_found[0]]\n",
    "            \n",
    "            if has_comparison:\n",
    "                # Find the parts before and after \"比\"\n",
    "                parts_before = [part for part in mentioned_parts \n",
    "                              if item.find(part) < item.find('比')]\n",
    "                parts_after = [part for part in mentioned_parts \n",
    "                             if item.find(part) > item.find('比')]\n",
    "                \n",
    "                # Assign opposite values for parts before \"比\"\n",
    "                for part in parts_before:\n",
    "                    result[BODY_PARTS[part]] = desc_value\n",
    "                \n",
    "                # Assign normal values for parts after \"比\"\n",
    "                for part in parts_after:\n",
    "                    result[BODY_PARTS[part]] = 4 - desc_value\n",
    "            else:\n",
    "                # No comparison, assign same value to all parts\n",
    "                for part in mentioned_parts:\n",
    "                    result[BODY_PARTS[part]] = desc_value\n",
    "\n",
    "    # New Logic: Handle \"其他\" or \"其余\" with a description adjective\n",
    "    for item in items:\n",
    "        if any(keyword in item for keyword in ['其他', '其余']):\n",
    "            # Find description adjectives in the item\n",
    "            descriptions_found = []\n",
    "            for desc in DESCRIPTIONS.keys():\n",
    "                if desc == '长':\n",
    "                    # Ensure '长' is not part of '长度'\n",
    "                    if '长' in item and '长度' not in item:\n",
    "                        descriptions_found.append(desc)\n",
    "                else:\n",
    "                    if desc in item:\n",
    "                        descriptions_found.append(desc)\n",
    "            \n",
    "            if descriptions_found:\n",
    "                # Use the first found description\n",
    "                desc_value = DESCRIPTIONS[descriptions_found[0]]\n",
    "                \n",
    "                # Assign to all body parts that are still None\n",
    "                for part, col in BODY_PARTS.items():\n",
    "                    if result[col] is None:\n",
    "                        result[col] = desc_value\n",
    "                break  # Assuming only one \"其他\" or \"其余\" per text\n",
    "\n",
    "    # Check if all body part values are still None\n",
    "    body_values = [result[col] for col in BODY_PARTS.values()]\n",
    "    if all(v is None for v in body_values):\n",
    "        result['noinfo'] = 1\n",
    "    else:\n",
    "        result['noinfo'] = 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "def process_csv(input_file, output_file):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Initialize new columns\n",
    "    df['invalid'] = 0\n",
    "    df['noinfo'] = 0\n",
    "    df['neck_value'] = None\n",
    "    df['head_value'] = None\n",
    "    df['leg_value'] = None\n",
    "    df['tail_value'] = None\n",
    "    \n",
    "    # Apply the extraction function to each row\n",
    "    extracted_data = df['text'].apply(extract_values)\n",
    "    \n",
    "    # Populate the new columns based on the extracted data\n",
    "    df['invalid'] = extracted_data.apply(lambda x: x['invalid'])\n",
    "    df['noinfo'] = extracted_data.apply(lambda x: x['noinfo'])\n",
    "    df['neck_value'] = extracted_data.apply(lambda x: x['neck_value'])\n",
    "    df['head_value'] = extracted_data.apply(lambda x: x['head_value'])\n",
    "    df['leg_value'] = extracted_data.apply(lambda x: x['leg_value'])\n",
    "    df['tail_value'] = extracted_data.apply(lambda x: x['tail_value'])\n",
    "    \n",
    "    # Save the processed DataFrame to a new CSV file\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Example usage:\n",
    "# process_csv('recording.csv', 'processed_recording.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(project_root) / 'data' / 'raw' / 'Task2'\n",
    "output_dir = Path(project_root) / 'data' / 'processed' / 'Task2' \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('rec.csv'):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(input_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(input_path, encoding='gbk')\n",
    "        \n",
    "        process_csv(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.colors as mc\n",
    "import colorsys\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(input_rec_csv, input_bhv_csv, input_modelfitting):\n",
    "    \"\"\"\n",
    "    读取并合并三个数据文件。\n",
    "    \n",
    "    Parameters:\n",
    "        input_rec_csv (str): Task2_15_rec.csv 的路径。\n",
    "        input_bhv_csv (str): Task2_15_bhv.csv 的路径。\n",
    "        input_modelfitting (list): 包含模型拟合数据的列表，每个元素为 (k, center_dict)。\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 合并后的数据框，包含human_feature和choice特征。\n",
    "    \"\"\"\n",
    "    # 1. 读取CSV文件\n",
    "    try:\n",
    "        df_rec = pd.read_csv(input_rec_csv)\n",
    "        df_bhv = pd.read_csv(input_bhv_csv)\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"无法找到文件: {e.filename}\")\n",
    "    \n",
    "    # 2. 合并两个DataFrame，基于'iSession'和'iTrial'\n",
    "    if not {'iSession', 'iTrial'}.issubset(df_rec.columns):\n",
    "        raise ValueError(\"Task2_15_rec.csv中必须包含'iSession'和'iTrial'列。\")\n",
    "    if not {'iSession', 'iTrial', 'choice'}.issubset(df_bhv.columns):\n",
    "        raise ValueError(\"Task2_15_bhv.csv中必须包含'iSession', 'iTrial'和'choice'列。\")\n",
    "    \n",
    "    df = pd.merge(df_rec, df_bhv[['iSession', 'iTrial', 'choice']], on=['iSession', 'iTrial'], how='left')\n",
    "\n",
    "    # 3. 处理四个value列\n",
    "    value_columns = ['neck_value', 'head_value', 'leg_value', 'tail_value']\n",
    "    for col in value_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"列 '{col}' 在CSV文件中不存在。\")\n",
    "\n",
    "    # 4. 填充空值为2\n",
    "    df[value_columns] = df[value_columns].fillna(2)\n",
    "\n",
    "    # 5. 映射[1, 2, 3]到[0.25, 0.5, 0.75]\n",
    "    mapping = {1: 0.25, 2: 0.5, 3: 0.75}\n",
    "    df[value_columns] = df[value_columns].replace(mapping)\n",
    "\n",
    "    # 6. 重命名列\n",
    "    rename_mapping = {\n",
    "        'head_value': 'human_feature_1',\n",
    "        'leg_value': 'human_feature_2',\n",
    "        'tail_value': 'human_feature_3',\n",
    "        'neck_value': 'human_feature_4'\n",
    "    }\n",
    "    df1 = df.rename(columns=rename_mapping)\n",
    "\n",
    "    # 定义列名\n",
    "    columns = [f'choice_{choice}_feature_{feature}' \n",
    "            for choice in range(1, 5) \n",
    "            for feature in range(1, 5)]\n",
    "\n",
    "    # 提取数据行\n",
    "    rows = []\n",
    "    for entry in input_modelfitting:\n",
    "        k, center_dict = entry\n",
    "        row = []\n",
    "        for choice_key in range(4):  # 键 0 到 3\n",
    "            features = center_dict.get(choice_key, (None,)*4)\n",
    "            row.extend(features)\n",
    "        rows.append(row)\n",
    "\n",
    "    # 创建 DataFrame\n",
    "    df2 = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    result = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cube(ax):\n",
    "    \"\"\"\n",
    "    在给定的轴上绘制一个立方体。\n",
    "    \n",
    "    Parameters:\n",
    "        ax (Axes3D): 三维坐标轴对象。\n",
    "    \"\"\"\n",
    "    # 定义立方体的8个顶点\n",
    "    vertices = [\n",
    "        (0, 0, 0),\n",
    "        (1, 0, 0),\n",
    "        (1, 1, 0),\n",
    "        (0, 1, 0),\n",
    "        (0, 0, 1),\n",
    "        (1, 0, 1),\n",
    "        (1, 1, 1),\n",
    "        (0, 1, 1)\n",
    "    ]\n",
    "    \n",
    "    # 定义立方体的12条边，连接顶点索引\n",
    "    edges = [\n",
    "        (0, 1), (1, 2), (2, 3), (3, 0),  # 底面\n",
    "        (4, 5), (5, 6), (6, 7), (7, 4),  # 顶面\n",
    "        (0, 4), (1, 5), (2, 6), (3, 7)   # 连接底面和顶面\n",
    "    ]\n",
    "    \n",
    "    # 绘制边线\n",
    "    for edge in edges:\n",
    "        start, end = edge\n",
    "        x_vals = [vertices[start][0], vertices[end][0]]\n",
    "        y_vals = [vertices[start][1], vertices[end][1]]\n",
    "        z_vals = [vertices[start][2], vertices[end][2]]\n",
    "        ax.plot(x_vals, y_vals, z_vals, color='grey')\n",
    "\n",
    "def draw_intersection_lines(ax):\n",
    "    \"\"\"\n",
    "    在给定的轴上绘制灰色的三个平面的交线，共六条。\n",
    "    \n",
    "    Parameters:\n",
    "        ax (Axes3D): 三维坐标轴对象。\n",
    "    \"\"\"\n",
    "    # 定义平面位置\n",
    "    plane_position = 0.5\n",
    "    \n",
    "    # # 绘制平面 feature1=0.5\n",
    "    # y, z = np.meshgrid(np.linspace(0, 1, 10), np.linspace(0, 1, 10))\n",
    "    # x = np.full_like(y, plane_position)\n",
    "    # ax.plot_surface(x, y, z, color='grey', alpha=0.07)\n",
    "    \n",
    "    # # 绘制平面 feature2=0.5\n",
    "    # x, z = np.meshgrid(np.linspace(0, 1, 10), np.linspace(0, 1, 10))\n",
    "    # y = np.full_like(x, plane_position)\n",
    "    # ax.plot_surface(x, y, z, color='grey', alpha=0.07)\n",
    "    \n",
    "    # # 绘制平面 feature3=0.5\n",
    "    # x, y = np.meshgrid(np.linspace(0, 1, 10), np.linspace(0, 1, 10))\n",
    "    # z = np.full_like(x, plane_position)\n",
    "    # ax.plot_surface(x, y, z, color='grey', alpha=0.07)\n",
    "    \n",
    "    # 绘制交线（六条）\n",
    "    # 1. feature1=0.5 与 feature2=0.5 的交线 (x=0.5, y=0.5, z从0到1)\n",
    "    ax.plot([plane_position, plane_position], [plane_position, plane_position], [0, 1], color='grey', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # 2. feature1=0.5 与 feature3=0.5 的交线 (x=0.5, y从0到1, z=0.5)\n",
    "    ax.plot([plane_position, plane_position], [0, 1], [plane_position, plane_position], color='grey', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # 3. feature2=0.5 与 feature3=0.5 的交线 (x从0到1, y=0.5, z=0.5)\n",
    "    ax.plot([0, 1], [plane_position, plane_position], [plane_position, plane_position], color='grey', linestyle='--', linewidth=1)\n",
    "\n",
    "def lighten_color(color, amount=0.5):\n",
    "    \"\"\"\n",
    "    淡化颜色，使其更浅。\n",
    "\n",
    "    Parameters:\n",
    "        color (str): 原始颜色名称或RGB值。\n",
    "        amount (float): 淡化程度，0表示不变，1表示白色。\n",
    "\n",
    "    Returns:\n",
    "        tuple: 淡化后的RGB颜色。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    # 淡化颜色\n",
    "    new_color = colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])\n",
    "    return new_color\n",
    "\n",
    "def plot_choice_graph(iSub, iSession, iTrial, choice, features_list, color_mapping, plots_dir, plot_side='both'):\n",
    "    \"\"\"\n",
    "    绘制特定 choice 值的图像，并保存。\n",
    "    \n",
    "    Parameters:\n",
    "        iSub (int/str): 受试者编号。\n",
    "        iSession (int/str): 会话编号。\n",
    "        iTrial (int/str): 试验编号。\n",
    "        choice (int): 当前的 choice 值（1, 2, 3, 4）。\n",
    "        features (list or tuple): 当前行的特征值 [feature1, feature2, feature3, feature4]。\n",
    "        color_mapping (dict): 每个 choice 值对应的颜色映射。\n",
    "        plots_dir (str): 图像保存的文件夹路径。\n",
    "        plot_side (str): 绘制的子图类型，可选 'left', 'right', 'both'。\n",
    "    \"\"\"\n",
    "    # 创建对应 choice 的子文件夹路径\n",
    "    choice_folder = os.path.join(plots_dir, f\"choice{choice}\")\n",
    "    if not os.path.exists(choice_folder):\n",
    "        os.makedirs(choice_folder)\n",
    "    \n",
    "    # 创建图表\n",
    "    fig = plt.figure(figsize=(12, 6) if plot_side == 'both' else (6, 6))\n",
    "    \n",
    "    # 添加主标题\n",
    "    fig.suptitle(f\"iSub={iSub}, iSession={iSession}, iTrial={iTrial}, Category={choice}\", fontsize=16)\n",
    "\n",
    "    # Prepare yellow point coordinates\n",
    "    yellow_point_coords = {\n",
    "        1: (0.25, 0.25, 0.5),\n",
    "        2: (0.25, 0.75, 0.5),\n",
    "        3: (0.75, 0.5, 0.25),\n",
    "        4: (0.75, 0.5, 0.75)\n",
    "    }\n",
    "\n",
    "    # Extract all human and Bayesian learner features for trajectory\n",
    "    human_x = [feat['human_feature_1'] for feat in features_list]\n",
    "    human_y = [feat['human_feature_2'] for feat in features_list]\n",
    "    human_z = [feat['human_feature_3'] for feat in features_list]\n",
    "\n",
    "    bayesian_x = [feat[f'choice_{choice}_feature_1'] for feat in features_list]\n",
    "    bayesian_y = [feat[f'choice_{choice}_feature_2'] for feat in features_list]\n",
    "    bayesian_z = [feat[f'choice_{choice}_feature_3'] for feat in features_list]\n",
    "\n",
    "    # 绘制左图（human_feature_1, human_feature_2, human_feature_3）\n",
    "    if plot_side in ['left', 'both']:\n",
    "        ax_left = fig.add_subplot(1, 2, 1, projection='3d') if plot_side == 'both' else fig.add_subplot(1, 1, 1, projection='3d')\n",
    "        draw_cube(ax_left)\n",
    "\n",
    "        # 淡化后的颜色\n",
    "        lighter_color = lighten_color(color_mapping[choice], amount=0.7)\n",
    "\n",
    "        # 目标点\n",
    "        if choice in yellow_point_coords:\n",
    "            y_point = yellow_point_coords[choice]\n",
    "            ax_left.scatter(*y_point, color='yellow', s=200, alpha=0.7, edgecolors='k')\n",
    "\n",
    "        # Plot trajectory line\n",
    "        if len(features_list) > 1:\n",
    "            ax_left.plot(human_x, human_y, human_z, color=lighter_color, linewidth=1)\n",
    "        # Plot current point\n",
    "        ax_left.scatter(human_x[-1], human_y[-1], human_z[-1], color=color_mapping[choice], s=100, alpha=0.8, edgecolors='w')\n",
    "        # 设置坐标轴刻度\n",
    "        ax_left.set_xticks([0, 0.5, 1])\n",
    "        ax_left.set_yticks([0, 0.5, 1])\n",
    "        ax_left.set_zticks([0, 0.5, 1])\n",
    "        ax_left.set_xlim(0, 1)\n",
    "        ax_left.set_ylim(0, 1)\n",
    "        ax_left.set_zlim(0, 1)\n",
    "        ax_left.set_xlabel('Feature 1')\n",
    "        ax_left.set_ylabel('Feature 2')\n",
    "        ax_left.set_zlabel('Feature 3')\n",
    "        ax_left.view_init(elev=15., azim=30)  # 调整视角\n",
    "        # 绘制平面和交线\n",
    "        # draw_intersection_lines(ax_left)\n",
    "        # 添加子图标题\n",
    "        ax_left.set_title(\"Human\")\n",
    "\n",
    "    # 绘制右图（feature2, 3, 4）\n",
    "    if plot_side in ['right', 'both']:\n",
    "        if plot_side == 'both':\n",
    "            ax_right = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "        else:\n",
    "            ax_right = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "        draw_cube(ax_right)\n",
    "\n",
    "        # 淡化后的颜色\n",
    "        lighter_color = lighten_color(color_mapping[choice], amount=0.7)\n",
    "\n",
    "        # 目标点\n",
    "        if choice in yellow_point_coords:\n",
    "            y_point = yellow_point_coords[choice]\n",
    "            ax_right.scatter(*y_point, color='yellow', s=200, alpha=0.7, edgecolors='k')\n",
    "        \n",
    "        # Plot trajectory line\n",
    "        if len(features_list) > 1:\n",
    "            ax_right.plot(bayesian_x, bayesian_y, bayesian_z, color=lighter_color, linewidth=1)\n",
    "        # Plot current point\n",
    "        ax_right.scatter(bayesian_x[-1], bayesian_y[-1], bayesian_z[-1], color=color_mapping[choice], s=100, alpha=0.8, edgecolors='w')\n",
    "        # 设置坐标轴刻度\n",
    "        ax_right.set_xticks([0, 0.5, 1])\n",
    "        ax_right.set_yticks([0, 0.5, 1])\n",
    "        ax_right.set_zticks([0, 0.5, 1])\n",
    "        ax_right.set_xlim(0, 1)\n",
    "        ax_right.set_ylim(0, 1)\n",
    "        ax_right.set_zlim(0, 1)\n",
    "        ax_right.set_xlabel('Feature 1')\n",
    "        ax_right.set_ylabel('Feature 2')\n",
    "        ax_right.set_zlabel('Feature 3')\n",
    "        ax_right.view_init(elev=15., azim=30)  # 调整视角\n",
    "        # 绘制平面和交线\n",
    "        # draw_intersection_lines(ax_right)\n",
    "        # 添加子图标题\n",
    "        ax_right.set_title(\"Bayesian learner\")\n",
    "    \n",
    "    # 保存图表到对应的 choice 文件夹\n",
    "    filename = f\"{iSub}_{iSession}_{iTrial}_c{choice}.png\"\n",
    "    filepath = os.path.join(choice_folder, filename)\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "\n",
    "def process_and_plot(input_rec_csv, input_bhv_csv, input_modelfitting, output_csv, plots_dir, plot_side='both'):\n",
    "    \"\"\"\n",
    "    处理数据并生成按 choice 分别绘制的图像。\n",
    "    \n",
    "    Parameters:\n",
    "        input_rec_csv (str): Task2_15_rec.csv 的路径。\n",
    "        input_bhv_csv (str): Task2_15_bhv.csv 的路径。\n",
    "        input_modelfitting (list): 包含模型拟合数据的列表，每个元素为 (k, center_dict)。\n",
    "        output_csv (str): 处理后的CSV文件保存路径。\n",
    "        plots_dir (str): 图像保存的文件夹路径。\n",
    "        plot_side (str): 绘制的子图类型，可选 'left', 'right', 'both'。\n",
    "    \"\"\"\n",
    "    # 1. 读取并合并数据\n",
    "    df = read_data(input_rec_csv, input_bhv_csv, input_modelfitting)\n",
    "    \n",
    "    # 3. 保存处理后的CSV\n",
    "    df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 4. 创建各个 choice 的子文件夹\n",
    "    for choice in range(1, 5):\n",
    "        folder_name = f\"choice{choice}\"\n",
    "        folder_path = os.path.join(plots_dir, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "    \n",
    "    # 5. 定义颜色映射\n",
    "    color_mapping = {\n",
    "        1: 'darkgreen',\n",
    "        2: 'darkgreen',\n",
    "        3: 'darkred',\n",
    "        4: 'darkred'\n",
    "    }\n",
    "    \n",
    "    # 6. 初始化 last_known_features\n",
    "    # last_known_features = {choice: [feature_dict1, feature_dict2, ...]}\n",
    "    last_known_features = {1: [], 2: [], 3: [], 4: []}\n",
    "    \n",
    "    # 7. 迭代每一行数据，生成图表\n",
    "    for index, row in df.iterrows():\n",
    "        iSub = row.get('iSub', 'Unknown')  # 假设有 'iSub' 列\n",
    "        iSession = row['iSession']\n",
    "        iTrial = row['iTrial']\n",
    "        current_choice = row['choice']\n",
    "        \n",
    "        if pd.isna(current_choice):\n",
    "            print(f\"第 {index} 行缺少 'choice' 数据，跳过绘图。\")\n",
    "            continue\n",
    "        \n",
    "        current_choice = int(current_choice)\n",
    "        # 提取human_feature\n",
    "        human_features = {\n",
    "            'human_feature_1': row['human_feature_1'],\n",
    "            'human_feature_2': row['human_feature_2'],\n",
    "            'human_feature_3': row['human_feature_3'],\n",
    "            'human_feature_4': row['human_feature_4']\n",
    "        }\n",
    "        # 提取choice特征\n",
    "        choice_features = {}\n",
    "        for choice in range(1, 5):\n",
    "            choice_features[f'choice_{choice}_feature_1'] = row[f'choice_{choice}_feature_1']\n",
    "            choice_features[f'choice_{choice}_feature_2'] = row[f'choice_{choice}_feature_2']\n",
    "            choice_features[f'choice_{choice}_feature_3'] = row[f'choice_{choice}_feature_3']\n",
    "            choice_features[f'choice_{choice}_feature_4'] = row[f'choice_{choice}_feature_4']\n",
    "        \n",
    "        # 更新 last_known_features for the current_choice\n",
    "        feature_entry = {\n",
    "            'human_feature_1': human_features['human_feature_1'],\n",
    "            'human_feature_2': human_features['human_feature_2'],\n",
    "            'human_feature_3': human_features['human_feature_3'],\n",
    "            'human_feature_4': human_features['human_feature_4'],\n",
    "            f'choice_{current_choice}_feature_1': choice_features[f'choice_{current_choice}_feature_1'],\n",
    "            f'choice_{current_choice}_feature_2': choice_features[f'choice_{current_choice}_feature_2'],\n",
    "            f'choice_{current_choice}_feature_3': choice_features[f'choice_{current_choice}_feature_3'],\n",
    "            f'choice_{current_choice}_feature_4': choice_features[f'choice_{current_choice}_feature_4']\n",
    "        }\n",
    "        last_known_features[current_choice].append(feature_entry)\n",
    "        \n",
    "        # 绘制当前 choice 的图像\n",
    "        plot_choice_graph(\n",
    "            iSub=iSub,\n",
    "            iSession=iSession,\n",
    "            iTrial=iTrial,\n",
    "            choice=current_choice,\n",
    "            features_list=last_known_features[current_choice],\n",
    "            color_mapping=color_mapping,\n",
    "            plots_dir=plots_dir,\n",
    "            plot_side=plot_side\n",
    "        )\n",
    "    \n",
    "        # 绘制其他 choices 的图像，使用 last_known_features\n",
    "        for choice in range(1, 5):\n",
    "            if choice == current_choice:\n",
    "                continue  # 已经绘制当前选择的 choice\n",
    "            if last_known_features[choice]:\n",
    "                # 绘制该 choice 的图像，使用上一次已知的特征值\n",
    "                plot_choice_graph(\n",
    "                    iSub=iSub,\n",
    "                    iSession=iSession,\n",
    "                    iTrial=iTrial,\n",
    "                    choice=choice,\n",
    "                    features_list=last_known_features[choice],\n",
    "                    color_mapping=color_mapping,\n",
    "                    plots_dir=plots_dir,\n",
    "                    plot_side=plot_side\n",
    "                )\n",
    "            else:\n",
    "                # 如果该 choice 之前没有数据，则跳过或使用默认图像\n",
    "                print(f\"Choice {choice} 在第 {index} 行之前没有数据，跳过生成图像。\")\n",
    "\n",
    "    print(f\"处理完成，图表已分别保存到 '{plots_dir}/choice1', '{plots_dir}/choice2', '{plots_dir}/choice3', 和 '{plots_dir}/choice4' 文件夹中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = Path(project_root) / 'results' / 'Bayesian'\n",
    "fitting_results = joblib.load(result_path / 'M_Base_fitting_results.joblib')\n",
    "fit_result = fitting_results[9]\n",
    "step_results = fit_result['step_results']\n",
    "\n",
    "# 导入分割方法\n",
    "import src.Bayesian.utils.partition as partition\n",
    "importlib.reload(partition)\n",
    "from src.Bayesian.utils.partition import Partition\n",
    "\n",
    "partition = Partition()\n",
    "all_centers = partition.get_centers(4, 4)\n",
    "\n",
    "input_modelfitting = [[step['k'], all_centers[step['k'] - 1][1]] for step in step_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice 1 在第 0 行之前没有数据，跳过生成图像。\n",
      "Choice 2 在第 0 行之前没有数据，跳过生成图像。\n",
      "Choice 3 在第 0 行之前没有数据，跳过生成图像。\n",
      "Choice 1 在第 1 行之前没有数据，跳过生成图像。\n",
      "Choice 2 在第 1 行之前没有数据，跳过生成图像。\n",
      "Choice 1 在第 2 行之前没有数据，跳过生成图像。\n",
      "Choice 1 在第 3 行之前没有数据，跳过生成图像。\n",
      "处理完成，图表已分别保存到 '/home/yangjiong/CategoryLearning/results/Plots/choice1', '/home/yangjiong/CategoryLearning/results/Plots/choice2', '/home/yangjiong/CategoryLearning/results/Plots/choice3', 和 '/home/yangjiong/CategoryLearning/results/Plots/choice4' 文件夹中。\n"
     ]
    }
   ],
   "source": [
    "raw_dir = Path(project_root) / 'data' / 'raw' / 'Task2' \n",
    "processed_dir = Path(project_root) / 'data' / 'processed' / 'Task2' \n",
    "input_bhv_csv = os.path.join(raw_dir, 'Task2_9_bhv.csv')\n",
    "input_rec_csv = os.path.join(processed_dir, 'Task2_9_rec.csv')\n",
    "output_csv = os.path.join(processed_dir, 'Task2_9_processed.csv')\n",
    "plots_dir = Path(project_root) / 'results' / 'Plots'\n",
    "\n",
    "process_and_plot(input_rec_csv, input_bhv_csv, input_modelfitting, output_csv, plots_dir, plot_side='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import imageio\n",
    "\n",
    "def extract_session_trial(filename, pattern):\n",
    "    \"\"\"\n",
    "    从文件名中提取iSession和iTrial。\n",
    "\n",
    "    参数:\n",
    "    - filename (str): 文件名。\n",
    "    - pattern (str): 用于匹配文件名的正则表达式模式。\n",
    "\n",
    "    返回:\n",
    "    - tuple: (iSession, iTrial) 如果匹配成功，否则 (None, None)。\n",
    "    \"\"\"\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        iSession = int(match.group(1))\n",
    "        iTrial = int(match.group(2))\n",
    "        return iSession, iTrial\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def create_sorted_gif(plots_dir, output_gif, pattern, duration=0.5):\n",
    "    \"\"\"\n",
    "    将指定文件夹中的所有PNG图像按照iSession和iTrial的顺序合成为一个GIF文件。\n",
    "\n",
    "    参数:\n",
    "    - plots_dir (Path): 存放PNG图像的子文件夹路径。\n",
    "    - output_gif (Path): 输出GIF文件的路径。\n",
    "    - pattern (str): 用于匹配文件名的正则表达式模式。\n",
    "    - duration (float): 每帧之间的时间间隔（秒）。\n",
    "    \"\"\"\n",
    "    # 获取所有PNG文件\n",
    "    all_files = [f for f in os.listdir(plots_dir) if f.endswith('.png')]\n",
    "\n",
    "    # 提取iSession和iTrial，并过滤无效文件\n",
    "    valid_files = []\n",
    "    for f in all_files:\n",
    "        iSession, iTrial = extract_session_trial(f, pattern)\n",
    "        if iSession is not None and iTrial is not None:\n",
    "            valid_files.append((iSession, iTrial, f))\n",
    "        else:\n",
    "            print(f\"文件名 '{f}' 不符合预期格式，已跳过。\")\n",
    "\n",
    "    if not valid_files:\n",
    "        print(f\"在文件夹 '{plots_dir}' 中未找到符合格式的PNG图像。\")\n",
    "        return\n",
    "\n",
    "    # 按iSession和iTrial排序\n",
    "    sorted_files = sorted(valid_files, key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    # 读取图像\n",
    "    images = []\n",
    "    for iSession, iTrial, filename in sorted_files:\n",
    "        filepath = plots_dir / filename\n",
    "        try:\n",
    "            images.append(imageio.imread(filepath))\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件 '{filepath}' 时出错: {e}\")\n",
    "\n",
    "    if not images:\n",
    "        print(f\"没有成功读取任何图像用于 '{output_gif}'。\")\n",
    "        return\n",
    "\n",
    "    # 创建GIF\n",
    "    try:\n",
    "        imageio.mimsave(output_gif, images, duration=duration)\n",
    "        print(f\"GIF已成功创建并保存为 '{output_gif}'。\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存GIF '{output_gif}' 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3643890/3522792649.py:58: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(filepath))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF已成功创建并保存为 '/home/yangjiong/CategoryLearning/results/Plots/choice1_animation.gif'。\n",
      "GIF已成功创建并保存为 '/home/yangjiong/CategoryLearning/results/Plots/choice2_animation.gif'。\n",
      "GIF已成功创建并保存为 '/home/yangjiong/CategoryLearning/results/Plots/choice3_animation.gif'。\n",
      "GIF已成功创建并保存为 '/home/yangjiong/CategoryLearning/results/Plots/choice4_animation.gif'。\n"
     ]
    }
   ],
   "source": [
    "plots_parent_dir = Path(project_root) / 'results' / 'Plots' \n",
    "\n",
    "# 定义子文件夹及对应的文件名模式\n",
    "choices = {\n",
    "    'choice1': r'^\\d+_(\\d+)_(\\d+)_c1\\.png$',\n",
    "    'choice2': r'^\\d+_(\\d+)_(\\d+)_c2\\.png$',\n",
    "    'choice3': r'^\\d+_(\\d+)_(\\d+)_c3\\.png$',\n",
    "    'choice4': r'^\\d+_(\\d+)_(\\d+)_c4\\.png$',\n",
    "}\n",
    "\n",
    "# 遍历每个子文件夹并生成GIF\n",
    "for choice, pattern in choices.items():\n",
    "    sub_dir = plots_parent_dir / choice\n",
    "    if not sub_dir.exists() or not sub_dir.is_dir():\n",
    "        print(f\"子文件夹 '{sub_dir}' 不存在或不是一个文件夹，已跳过。\")\n",
    "        continue\n",
    "\n",
    "    # 定义输出GIF的路径，保存到Plots父文件夹下\n",
    "    output_gif = plots_parent_dir / f'{choice}_animation.gif'\n",
    "\n",
    "    # 创建GIF\n",
    "    create_sorted_gif(sub_dir, output_gif, pattern, duration=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
