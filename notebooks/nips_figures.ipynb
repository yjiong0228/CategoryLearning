{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897e9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa650a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取项目根目录\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# 导入数据\n",
    "processed_path = Path(project_root) / 'data' / 'processed'\n",
    "learning_data = pd.read_csv(processed_path / 'Task2_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98000651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.Bayesian_new.problems.model as model\n",
    "importlib.reload(model)\n",
    "from src.Bayesian_new.problems.model import SingleRationalModel\n",
    "\n",
    "import src.Bayesian_new.problems.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian_new.problems.config import config_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b0eb0",
   "metadata": {},
   "source": [
    "#### Fig 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d69daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nips_plot as nips_plot\n",
    "importlib.reload(nips_plot)\n",
    "from src.nips_plot import Fig1_Ntrial\n",
    "\n",
    "# 初始化处理器\n",
    "plot_fig1_ntrial = Fig1_Ntrial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "457917f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig1C_ntrial.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig1_ntrial.plot_trial_number(learning_data,\n",
    "                                figsize=(4, 5),\n",
    "                                color_1='#A6A6A6',\n",
    "                                color_2='#A6A6A6',\n",
    "                                color_3='#A6A6A6',\n",
    "                                label_1='Exp 1',\n",
    "                                label_2='Exp 2',\n",
    "                                label_3='Exp 3',\n",
    "                                save_path=plots_dir / 'Fig1C_ntrial.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7cc2f3",
   "metadata": {},
   "source": [
    "#### Fig 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1efe2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nips_plot as nips_plot\n",
    "importlib.reload(nips_plot)\n",
    "from src.nips_plot import Fig1_Acc\n",
    "\n",
    "# 初始化处理器\n",
    "plot_fig1_acc = Fig1_Acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fb12c3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig1D_accuracy.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig1_acc.plot_accuracy(learning_data,\n",
    "                    block_size= 64,\n",
    "                    figsize=(15, 5),\n",
    "                    widths=(0.46,1.6,0.83),\n",
    "                    save_path=plots_dir / 'Fig1D_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3600476",
   "metadata": {},
   "source": [
    "#### Fig 1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3898d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nips_plot as nips_plot\n",
    "importlib.reload(nips_plot)\n",
    "from src.nips_plot import Fig1_Oral\n",
    "\n",
    "# 初始化处理器\n",
    "plot_fig1_oral = Fig1_Oral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ac29cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入被试数据\n",
    "iSub = 7\n",
    "subject_data = learning_data[learning_data['iSub'] == iSub]\n",
    "subject_data = subject_data.reset_index(drop=True)\n",
    "ncats=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成：仅绘制行 [125]，图表已保存至 /home/yangjiong/CategoryLearning/results/Nips_figures/choice*/ 文件夹。\n"
     ]
    }
   ],
   "source": [
    "# 绘制单帧图片\n",
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures' \n",
    "plot_fig1_oral.plot_human_trajactory(ncats, subject_data, 1, plots_dir, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8137c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成：仅绘制行 [125]，图表已保存至 /home/yangjiong/CategoryLearning/results/Nips_figures/choice*/ 文件夹。\n"
     ]
    }
   ],
   "source": [
    "plot_fig1_oral.plot_human_trajactory(ncats, subject_data, 2, plots_dir, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bad448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型数据\n",
    "result_path = Path(project_root) / 'results' / 'Bayesian_new'\n",
    "fitting_results = joblib.load(result_path / 'M_Base_fitting_results.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "be43860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_result = fitting_results[iSub]\n",
    "step_results = sub_result['step_results']\n",
    "cond = sub_result['condition']\n",
    "\n",
    "model  = SingleRationalModel(config_base, condition=cond)\n",
    "model_centers = plot_fig1_oral.get_model_centers(step_results,\n",
    "                                                 model,\n",
    "                                                 ncats=ncats)\n",
    "model_centers['iSub']     = iSub\n",
    "model_centers['iTrial']   = model_centers.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "93b37107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成模型轨迹绘制：行 [10]，图表已保存至 /home/yangjiong/CategoryLearning/results/Nips_figures/choice*/ 文件夹。\n"
     ]
    }
   ],
   "source": [
    "# 绘制单帧图片\n",
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures' \n",
    "plot_fig1_oral.plot_model_trajactory(ncats, model_centers, 1, plots_dir, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e0442e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成模型轨迹绘制：行 [29]，图表已保存至 /home/yangjiong/CategoryLearning/results/Nips_figures/choice*/ 文件夹。\n"
     ]
    }
   ],
   "source": [
    "plot_fig1_oral.plot_model_trajactory(ncats, model_centers, 2, plots_dir, 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aac3c5",
   "metadata": {},
   "source": [
    "#### Fig 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71142464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载拟合结果\n",
    "base_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_new' / 'M_Base_fitting_results.joblib')\n",
    "forget_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_new' / 'M_Fgt_fitting_results_400.joblib')\n",
    "cluster_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_recon' / 'M_cl_max7_randp_k1_acc7.joblib')\n",
    "fgtcluster_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_recon' / 'M_fgt_cl.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0737e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(fitting_results, learning_data):\n",
    "    predict_results = {}\n",
    "\n",
    "    for i, (iSub, subject_data) in enumerate(learning_data.groupby('iSub')):\n",
    "        condition = subject_data['condition'].iloc[0]\n",
    "        model_base = SingleRationalModel(config_base, condition=condition)\n",
    "        s_data = (subject_data[[\"feature1\", \"feature2\", \"feature3\", \"feature4\"]].values,\n",
    "                subject_data[\"choice\"].values,\n",
    "                subject_data[\"feedback\"].values, \n",
    "                subject_data[\"category\"].values)\n",
    "        \n",
    "        step_results = fitting_results[iSub].get('step_results', fitting_results[iSub].get('best_step_results'))\n",
    "        results = model_base.predict_choice(s_data, step_results, use_cached_dist=False, window_size=16)\n",
    "\n",
    "        predict_results[iSub] = {\n",
    "            'condition': condition,\n",
    "            'true_acc': results['true_acc'],\n",
    "            'pred_acc': results['pred_acc'],\n",
    "            'sliding_true_acc': results['sliding_true_acc'],\n",
    "            'sliding_pred_acc': results['sliding_pred_acc'],\n",
    "            'sliding_pred_acc_std': results['sliding_pred_acc_std']\n",
    "        }\n",
    "    return predict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa712e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_predict_results = get_prediction(base_results, learning_data)\n",
    "# forget_predict_results = get_prediction(forget_results, learning_data)\n",
    "# cluster_predict_results = get_prediction(cluster_results, learning_data)\n",
    "fgtcluster_predict_results = get_prediction(fgtcluster_results, learning_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aeb6c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/yangjiong/CategoryLearning/results/Bayesian_recon/M_fgt_cluster_prediction.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(base_predict_results, Path(project_root) / 'results' / 'Bayesian_recon' / 'M_base_prediction.joblib')\n",
    "# joblib.dump(forget_predict_results, Path(project_root) / 'results' / 'Bayesian_recon' / 'M_fgt_prediction.joblib')\n",
    "# joblib.dump(cluster_predict_results, Path(project_root) / 'results' / 'Bayesian_recon' / 'M_cluster_prediction.joblib')\n",
    "joblib.dump(fgtcluster_predict_results, Path(project_root) / 'results' / 'Bayesian_recon' / 'M_fgt_cluster_prediction.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ff65235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载结果\n",
    "base_predict_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_recon' / 'M_base_prediction.joblib')\n",
    "forget_predict_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_recon' / 'M_fgt_prediction.joblib')\n",
    "cluster_predict_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_recon' / 'M_cluster_prediction.joblib')\n",
    "fgtcluster_predict_results = joblib.load(Path(project_root) / 'results' / 'Bayesian_recon' / 'M_fgt_cluster_prediction.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c668fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nips_plot as nips_plot\n",
    "importlib.reload(nips_plot)\n",
    "from src.nips_plot import Fig3_Group\n",
    "\n",
    "# 初始化处理器\n",
    "plot_fig3 = Fig3_Group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "030b871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3B_acc_error.png\n",
      "Raw p-values:         [0.     0.     0.0857]\n",
      "Corrected p-values (fdr_bh): [0.     0.     0.0857]\n",
      "Reject null hypotheses: [ True  True False]\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3.plot_group_acc_error(results_1=base_predict_results,\n",
    "                              results_2=cluster_predict_results,\n",
    "                              results_3=forget_predict_results,\n",
    "                              results_4=fgtcluster_predict_results,\n",
    "                              mc_method='fdr_bh',\n",
    "                              figsize=(6, 5),\n",
    "                              color_1='#DDAA33',\n",
    "                              color_2='#478ECC',\n",
    "                              color_3='#45B53F',\n",
    "                              color_4='#F39972',\n",
    "                              label_1='Base',\n",
    "                              label_2='Jump',\n",
    "                              label_3='Forget',\n",
    "                              label_4='Fgt+Jump',\n",
    "                              save_path=plots_dir / 'Fig3B_acc_error.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1545112",
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_hypo_hits = joblib.load(Path(project_root) / 'results' / 'Bayesian_recon' / 'oral_hypo_hits.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03a03ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3B_k_corr.png\n",
      "Raw p-values:         [0.     0.     0.0002]\n",
      "Corrected p-values (fdr_bh): [0.     0.     0.0002]\n",
      "Reject null hypotheses: [ True  True  True]\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3.plot_group_k_corr(oral_hypo_hits=oral_hypo_hits,\n",
    "                             results_1=base_results,\n",
    "                              results_2=cluster_results,\n",
    "                              results_3=forget_results,\n",
    "                              results_4=fgtcluster_results,\n",
    "                              mc_method='fdr_bh',\n",
    "                              figsize=(6, 5),\n",
    "                              color_1='#DDAA33',\n",
    "                              color_2='#478ECC',\n",
    "                              color_3='#45B53F',\n",
    "                              color_4='#F39972',\n",
    "                              label_1='Base',\n",
    "                              label_2='Jump',\n",
    "                              label_3='Forget',\n",
    "                              label_4='Fgt+Jump',\n",
    "                              save_path=plots_dir / 'Fig3B_k_corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8475752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw p-values: [0.001  0.     0.0001]\n",
      "Corrected p-values (fdr_bh): [0.001  0.     0.0001]\n",
      "Reject: [ True  True  True]\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3.plot_group_aic(results_1=base_results,\n",
    "                              results_2=cluster_results,\n",
    "                              results_3=forget_results,\n",
    "                              results_4=fgtcluster_results,\n",
    "                              mc_method='fdr_bh',\n",
    "                              figsize=(6, 5),\n",
    "                              color_1='#DDAA33',\n",
    "                              color_2='#478ECC',\n",
    "                              color_3='#45B53F',\n",
    "                              color_4='#F39972',\n",
    "                              label_1='Base',\n",
    "                              label_2='Jump',\n",
    "                              label_3='Forget',\n",
    "                              label_4='Fgt+Jump',\n",
    "                              save_path=plots_dir / 'Fig3B_aic.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f051c5f",
   "metadata": {},
   "source": [
    "#### Fig 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca8f22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nips_plot as nips_plot\n",
    "importlib.reload(nips_plot)\n",
    "from src.nips_plot import Fig3_Individual\n",
    "\n",
    "# 初始化处理器\n",
    "plot_fig3_individual = Fig3_Individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0440485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3C_fgt_cluster_21.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "subject_id = 21\n",
    "plot_fig3_individual.plot_acc_comparison(results=fgtcluster_predict_results,\n",
    "                              subject_id=subject_id,\n",
    "                              figsize=(5, 5),\n",
    "                              color='#F39972',\n",
    "                              color_true='#A6A6A6',\n",
    "                              label='Fgt+Jump',\n",
    "                              save_path=plots_dir / f'Fig3C_fgt_cluster_{subject_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac6e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3C_fgt.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3_individual.plot_acc_comparison(results=forget_predict_results,\n",
    "                              subject_id=14,\n",
    "                              figsize=(7, 5),\n",
    "                              color='#45B53F',\n",
    "                              color_true='#A6A6A6',\n",
    "                              label='Forget',\n",
    "                              save_path=plots_dir / 'Fig3C_fgt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3C_cluster.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3_individual.plot_acc_comparison(results=cluster_predict_results,\n",
    "                              subject_id=14,\n",
    "                              figsize=(7, 5),\n",
    "                              color='#478ECC',\n",
    "                              color_true='#A6A6A6',\n",
    "                              label='Jump',\n",
    "                              save_path=plots_dir / 'Fig3C_cluster.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e63e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3C_base.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3_individual.plot_acc_comparison(results=base_predict_results,\n",
    "                              subject_id=14,\n",
    "                              figsize=(7, 5),\n",
    "                              color='#DDAA33',\n",
    "                              color_true='#A6A6A6',\n",
    "                              label='Base',\n",
    "                              save_path=plots_dir / 'Fig3C_base.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad7c05b",
   "metadata": {},
   "source": [
    "#### Fig 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ddd17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nips_plot as nips_plot\n",
    "importlib.reload(nips_plot)\n",
    "from src.nips_plot import Fig3_Individual\n",
    "\n",
    "# 初始化处理器\n",
    "plot_fig3_individual = Fig3_Individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1046ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_hypos_list = {}\n",
    "\n",
    "for _, subj_df in learning_data.groupby('iSub'):\n",
    "    iSub   = int(subj_df['iSub'].iloc[0])\n",
    "    cond   = int(subj_df['condition'].iloc[0])\n",
    "    model  = SingleRationalModel(config_base, condition=cond)\n",
    "\n",
    "    centres = subj_df[['feature1_oral','feature2_oral',\n",
    "                       'feature3_oral','feature4_oral']].values\n",
    "    choices = subj_df['choice'].values\n",
    "\n",
    "    oral_hypos_list[iSub] = plot_fig3_individual.get_oral_hypos_list(cond,\n",
    "        (centres, choices), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea0cdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_hypo_hits = {}\n",
    "\n",
    "for iSub, hypos in oral_hypos_list.items():\n",
    "    condition = learning_data[learning_data['iSub'] ==\n",
    "                                iSub]['condition'].iloc[0]\n",
    "    target_value = 0 if condition == 1 else 42\n",
    "\n",
    "    hits = []  # 用于存储每个 trial 的 hit 值\n",
    "    for trial_hypos in hypos:\n",
    "        if not trial_hypos:\n",
    "            hits.append([])\n",
    "        else:\n",
    "            hits.append(1 if target_value in trial_hypos else 0)\n",
    "            # 计算hits的16试次滑动平均\n",
    "            numeric_hits = [h if isinstance(h, (int, float)) else 0 for h in hits]  # Convert non-numeric values to 0\n",
    "            rolling_hits = pd.Series(numeric_hits).rolling(window=16, min_periods=16).mean().tolist()\n",
    "            \n",
    "    oral_hypo_hits[iSub] = {\n",
    "        'iSub': iSub,\n",
    "        'condition': condition,\n",
    "        'hits': hits,\n",
    "        'rolling_hits': rolling_hits\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892ebd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/yangjiong/CategoryLearning/results/Bayesian_recon/oral_hypo_hits.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(oral_hypo_hits, Path(project_root) / 'results' / 'Bayesian_recon' / 'oral_hypo_hits.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a2137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fig3D] saved → /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3D_fgt_cluster_21.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "subject_id = 21\n",
    "plot_fig3_individual.plot_k_comparison(oral_hypo_hits,\n",
    "                             results=fgtcluster_results,\n",
    "                             subject_id=subject_id,\n",
    "                             figsize=(4, 3),\n",
    "                             color='#F39972',\n",
    "                             color_true='#A6A6A6',\n",
    "                             label='Fgt+Jump',\n",
    "                             save_path=plots_dir / f'Fig3D_fgt_cluster_{subject_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68cf0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fig3D] saved → /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3D_fgt.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3_individual.plot_k_comparison(oral_hypo_hits,\n",
    "                             results=forget_results,\n",
    "                             subject_id=14,\n",
    "                             figsize=(4, 3),\n",
    "                             color='#45B53F',\n",
    "                             color_true='#A6A6A6',\n",
    "                             label='Fgt',\n",
    "                             save_path=plots_dir / 'Fig3D_fgt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fig3D] saved → /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3D_cluster.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3_individual.plot_k_comparison(oral_hypo_hits,\n",
    "                             results=cluster_results,\n",
    "                             subject_id=14,\n",
    "                             figsize=(4, 3),\n",
    "                             color='#478ECC',\n",
    "                             color_true='#A6A6A6',\n",
    "                             label='Jump',\n",
    "                             save_path=plots_dir / 'Fig3D_cluster.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a5c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fig3D] saved → /home/yangjiong/CategoryLearning/results/Nips_figures/Fig3D_base.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig3_individual.plot_k_comparison(oral_hypo_hits,\n",
    "                             results=base_results,\n",
    "                             subject_id=14,\n",
    "                             figsize=(4, 3),\n",
    "                             color='#DDAA33',\n",
    "                             color_true='#A6A6A6',\n",
    "                             label='Base',\n",
    "                             save_path=plots_dir / 'Fig3D_base.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583b46d",
   "metadata": {},
   "source": [
    "#### Fig 4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nips_plot as nips_plot\n",
    "importlib.reload(nips_plot)\n",
    "from src.nips_plot import Fig4\n",
    "\n",
    "# 初始化处理器\n",
    "plot_fig4 = Fig4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e63a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/yangjiong/CategoryLearning/results/Nips_figures/Fig4A_amount.png\n"
     ]
    }
   ],
   "source": [
    "plots_dir = Path(project_root) / 'results' / 'Nips_figures'\n",
    "plot_fig4.plot_amount(results=fgtcluster_results,\n",
    "                             subject_id=14,\n",
    "                             figsize=(8, 5),\n",
    "                             color_1='#F39972',\n",
    "                             color_2='#A4A0B7',\n",
    "                             label_1='Exploitation',\n",
    "                             label_2='Exploration',\n",
    "                             save_path=plots_dir / 'Fig4A_amount.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
