{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Modeling ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定项目根目录\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "processed_path = Path(project_root) / 'data' / 'processed'\n",
    "learning_data = pd.read_csv(processed_path / 'Task2_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "from src.Bayesian_new import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Unit Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 0.1 Base Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Partition(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.calc_likelihood_entry(5, (np.array([[0.1,0.2,0.3,0.4],[0.1,0.4,0.3,0.2],[0.4,0.2,0.3,0.1]]), np.array([3,2,3]), np.array([1,0,1])), 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.calc_likelihood_entry(2, (np.array([[0.1,0.2,0.3,0.4],[0.1,0.2,0.3,0.4],[0.1,0.2,0.3,0.4]]), np.array([3,2,3]), np.array([1,0,1])), 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = PartitionLikelihood(BaseSet(range(10)), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.h_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.get_likelihood((np.array([[0.1,0.2,0.3,0.4],[0.05,0.02,0.53,0.4],[0.1,0.2,0.3,0.4]]), np.array([3,2,3]), np.array([1,1,0])), beta=15., normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl = SoftPartitionLikelihood(BaseSet(range(10)), p, np.exp(np.linspace(0,5,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spl.get_likelihood((np.array([[0.1,0.2,0.3,0.4],[0.05,0.02,0.53,0.4],[0.1,0.2,0.3,0.4]]), np.array([3,2,3]), np.array([1,1,0])), normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] BasePartition params: n_dims=4, n_cats=2\n"
     ]
    }
   ],
   "source": [
    "import src.Bayesian_new.problems.model as model\n",
    "importlib.reload(model)\n",
    "from src.Bayesian_new.problems.model import SingleRationalModel\n",
    "\n",
    "import src.Bayesian_new.problems.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian_new.problems.config import config_base\n",
    "\n",
    "base_model = SingleRationalModel(config_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] BasePartition params: n_dims=4, n_cats=4\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncats 2 [0 0 1 1 2 3 3 3 1 0 1 1 2 3 0 1 2 2 2 3 1 2 1 0 2 3 3 3 2 2 0 1 2 2 3 0 1\n",
      " 2 1 1 2 2 1 0 1 1 2 2 0 1 2 0 3 3 2 0 1 3 1 1 2 3 0 3 3 1 2 0 1 2 1 1 2 3\n",
      " 2 1 2 1 2 3 0 0 1 0 3 1 3 3 3 0 0 1 1 2 0 1 1 2 0 3 3 2 1 2 2 0 0 3 1 3 3\n",
      " 3 0 3 0 0 1 2 0 1 3 1 3 2 3 1 3 0 1 3 0 2 1 1 3 3 2 1 1 3 3 3 0 2 2 2 1 1\n",
      " 3 0 0 2 0 2 2 1 3 0 2 1 0 3 3 2 1 0 1 1 2 1 0 2 3 1 3 0 1 3 3 1 0 2 2 3 0\n",
      " 2 1 0 0 3 2 3 2 2 0 3 0 1 2 2 0 3 2 2 0 3 0 2 3 3 3 0 3 3 0 2 3 3 3 2 3 0\n",
      " 2 0 3 1 2 0 1 0 3 0 1 3 0 3 3 3 1 1 3 2 0 1 0 2 3 0 1 3 1 0 1 3 0 3 3 2 2\n",
      " 2 2 1 0 2 1 0 3 3 2 3 2 1 0 3 0 3 1 2 3 0 1 2 0 0 0 1 0 2 2 1 0 3 1 0 3 2\n",
      " 3 2 1 2 3 3 1 1 1 0 3 0 2 3 0 2 0 1 3 3 3 1 2 0 3 0 1 2 2 2 1 3 0 0 1 3 0\n",
      " 3 0 1 2 2 3 2 1 3 3 0 1 2 0 0 3 2 1 2 0 2 2 0 3 0 3 2 3 0 2 1 2 1 0 3 0 2\n",
      " 2 0 0 0 3 0 3 0 1 3 0 0 0 2 3 3 2 0 2 1 3 3 3 3 0 2 0 1 3 3 2 3 2 0 1 3 2\n",
      " 3 2 0 0 1 3 3 2 0 1 2 2 3 1 1 2 0 1 2 0 1 2 1 1 3 2 3 2 0 1 3 0 2 2 3 0 1\n",
      " 0 1 2 1 3 0 3 0 1 1 3 0 0 0 1 2 3 0 3 2 3 1 1 1 1 1 1 0 3 2 0 1 1 3 2 0 3\n",
      " 1 3 2 0 2 1 2 1 1 1 2 3 3 1 3 3 3 2 2 1 2 2 3 1 1 0 3 2 1 3 1 3 0 1 2 1 2\n",
      " 0 3 1 0 2 0 2 1 0 3 3 0 3 0 0 1 1 2 2 1 1 0 2 2 2 2 0 1 1 3 3 3 3 2 1 1 0\n",
      " 2 1 0 0 0 1 3 1 2 1 1 2 2 0 3 1 1 1 3 0 2 1 3 2 2 2 1 0 3 2 0 0 3 1 2 3 3\n",
      " 1 0 3 0 1 1 0 2 1 0 0 0 3 1 0 1 3 1 0 3 1 0 1 2 2 0 2 1 0 2 0 1 1 1 0 0 2\n",
      " 3 2 2 0 1 3 3 2 1 2 3 3 0 1 3 3 2 2 1 0 0 1 1 1 1 0 1 2 3 3 2 2 1 2 0 2 3\n",
      " 0 0 2 3 1 1 3 2 2 0 3 0 3 3 3 0 3 1 3 1 2 3 1 1 2 1 0 1 3 0 2 0 2 1 1 0 0\n",
      " 2] [[0.45411981 0.57458273 0.53734344 ... 0.5855737  0.59981094 0.44773864]\n",
      " [0.54588019 0.42541727 0.46265656 ... 0.4144263  0.40018906 0.55226136]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m s_data \u001b[38;5;241m=\u001b[39m (subject_data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature4\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     10\u001b[0m         subject_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoice\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     11\u001b[0m         subject_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(subject_data)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m step_results \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_trial_by_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m fitting_results[iSub] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m: condition,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_results\u001b[39m\u001b[38;5;124m'\u001b[39m: step_results\n\u001b[1;32m     17\u001b[0m }\n",
      "File \u001b[0;32m~/CategoryLearning/src/Bayesian_new/problems/model.py:197\u001b[0m, in \u001b[0;36mSingleRationalModel.fit_trial_by_trial\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(nTrial, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    196\u001b[0m     trial_data \u001b[38;5;241m=\u001b[39m [x[:step] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m--> 197\u001b[0m     best_params, best_ll, all_hypo_params, all_hypo_ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cached_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnTrial\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     all_hypo_post \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39minfer_log(\n\u001b[1;32m    201\u001b[0m         trial_data,\n\u001b[1;32m    202\u001b[0m         use_cached_dist\u001b[38;5;241m=\u001b[39m(step \u001b[38;5;241m!=\u001b[39m nTrial),\n\u001b[1;32m    203\u001b[0m         normalized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    205\u001b[0m     hypo_details \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/CategoryLearning/src/Bayesian_new/problems/model.py:169\u001b[0m, in \u001b[0;36mSingleRationalModel.fit\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mmaximum(likelihood, \u001b[38;5;241m0\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hypo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypotheses_set:\n\u001b[0;32m--> 169\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m_ll_per_hypo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparam_inits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparam_bounds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     beta_opt, ll_max \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39mresult\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m    174\u001b[0m     all_hypo_params[hypo] \u001b[38;5;241m=\u001b[39m ModelParams(hypo, beta_opt)\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/scipy/optimize/_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/scipy/optimize/lbfgsb.py:306\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m--> 306\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[1;32m    312\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/scipy/optimize/optimize.py:261\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    257\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:140\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CategoryLearning/src/Bayesian_new/problems/model.py:169\u001b[0m, in \u001b[0;36mSingleRationalModel.fit.<locals>.<lambda>\u001b[0;34m(beta)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mmaximum(likelihood, \u001b[38;5;241m0\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hypo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypotheses_set:\n\u001b[0;32m--> 169\u001b[0m     result \u001b[38;5;241m=\u001b[39m minimize(\u001b[38;5;28;01mlambda\u001b[39;00m beta: \u001b[38;5;241m-\u001b[39m\u001b[43m_ll_per_hypo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypo\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    170\u001b[0m                       x0\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_inits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m    171\u001b[0m                       bounds\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m    172\u001b[0m     beta_opt, ll_max \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39mresult\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m    174\u001b[0m     all_hypo_params[hypo] \u001b[38;5;241m=\u001b[39m ModelParams(hypo, beta_opt)\n",
      "File \u001b[0;32m~/CategoryLearning/src/Bayesian_new/problems/model.py:164\u001b[0m, in \u001b[0;36mSingleRationalModel.fit.<locals>._ll_per_hypo\u001b[0;34m(beta, hypo)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ll_per_hypo\u001b[39m(beta, hypo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 164\u001b[0m     likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_likelihood_entry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhypo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mmaximum(likelihood, \u001b[38;5;241m0\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/CategoryLearning/src/Bayesian_new/problems/partitions.py:142\u001b[0m, in \u001b[0;36mBasePartition.calc_likelihood_entry\u001b[0;34m(self, hypo, data, beta, use_cached_dist)\u001b[0m\n\u001b[1;32m    138\u001b[0m choices \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mncats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_cats, choices, prob)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(responses \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[43mprob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m prob[choices, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(choices))])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "# 模型拟合\n",
    "fitting_results = {}\n",
    "\n",
    "for i, (iSub, subject_data) in enumerate(learning_data.groupby('iSub')):\n",
    "    if iSub==2:\n",
    "        condition = subject_data['condition'].iloc[0]\n",
    "        model = SingleRationalModel(config_base, condition=condition)\n",
    "        print(iSub)\n",
    "        s_data = (subject_data[[\"feature1\", \"feature2\", \"feature3\", \"feature4\"]].values,\n",
    "                subject_data[\"choice\"].values,\n",
    "                subject_data[\"feedback\"].values)\n",
    "        # print(subject_data)\n",
    "        step_results = base_model.fit_trial_by_trial(s_data)\n",
    "        fitting_results[iSub] = {\n",
    "            'condition': condition,\n",
    "            'step_results': step_results\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_results = fitting_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_results = sub_results['step_results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Forget model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.Bayesian_new.problems.forget as forget\n",
    "importlib.reload(forget)\n",
    "from src.Bayesian_new.problems.forget import ForgetModel\n",
    "\n",
    "import src.Bayesian_new.problems.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian_new.problems.config import config_fgt\n",
    "\n",
    "forget_model = ForgetModel(config_fgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型拟合\n",
    "fitting_results = {}\n",
    "\n",
    "for i, (iSub, subject_data) in enumerate(learning_data.groupby('iSub')):\n",
    "    if iSub>1:\n",
    "        break\n",
    "    condition = subject_data['condition'].iloc[0]\n",
    "    model = ForgetModel(config_fgt, condition=condition)\n",
    "    print(iSub)\n",
    "    s_data = (subject_data[[\"feature1\", \"feature2\", \"feature3\", \"feature4\"]].values,\n",
    "              subject_data[\"choice\"].values,\n",
    "              subject_data[\"feedback\"].values, \n",
    "              subject_data[\"category\"].values)\n",
    "    # print(subject_data)\n",
    "    optimize_results = forget_model.optimize_params(s_data)\n",
    "    fitting_results[iSub] = {\n",
    "        'condition': condition,\n",
    "        'best_params': optimize_results['best_params'],\n",
    "        'best_error': optimize_results['best_error'],\n",
    "        'best_step_results': optimize_results['best_step_results'],\n",
    "        'optimize_results': optimize_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_results = fitting_results[1]['optimize_results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Base/ rational ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.Bayesian_new.problems.model as model\n",
    "importlib.reload(model)\n",
    "from src.Bayesian_new.problems.model import SingleRationalModel\n",
    "\n",
    "import src.Bayesian_new.problems.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian_new.problems.config import config_base\n",
    "\n",
    "base_model = SingleRationalModel(config_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装单个被试的拟合过程\n",
    "def process_subject(iSub, subject_data, config):\n",
    "    condition = subject_data['condition'].iloc[0]\n",
    "    model = SingleRationalModel(config, condition=condition)\n",
    "    \n",
    "    s_data = (subject_data[[\"feature1\", \"feature2\", \"feature3\", \"feature4\"]].values,\n",
    "              subject_data[\"choice\"].values,\n",
    "              subject_data[\"feedback\"].values)\n",
    "    # print(subject_data)\n",
    "    step_results = model.fit_trial_by_trial(s_data)\n",
    "    fitting_results[iSub] = {\n",
    "        'condition': condition,\n",
    "        'step_results': step_results\n",
    "    }\n",
    "\n",
    "# 并行拟合主流程\n",
    "def parallel_fitting(learning_data, config, n_jobs):\n",
    "    \"\"\"并行拟合所有被试\"\"\"\n",
    "    subjects = list(learning_data.groupby('iSub'))\n",
    "    \n",
    "    # 使用并行计算\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_subject)(iSub, sub_data, config)\n",
    "        for iSub, sub_data in tqdm(subjects, desc=\"Processing Subjects\")\n",
    "    )\n",
    "    \n",
    "    # 整理结果到字典\n",
    "    fitting_results = {res['iSub']: res for res in results}\n",
    "    return fitting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Subjects:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Subjects: 100%|██████████| 24/24 [00:00<00:00, 66.86it/s]\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 0/448 [00:00<?, ?it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  2%|▏         | 4/192 [00:00<00:05, 36.54it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  4%|▍         | 11/256 [00:00<00:04, 49.76it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  1%|          | 1/128 [00:00<00:14,  8.62it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 1/640 [00:00<01:41,  6.28it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 1/704 [00:00<02:14,  5.23it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 1/640 [00:00<01:50,  5.78it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  2%|▏         | 6/384 [00:00<00:13, 28.25it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  4%|▍         | 8/192 [00:00<00:05, 35.15it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 1/1344 [00:00<06:08,  3.64it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 1/512 [00:00<01:56,  4.40it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 1/640 [00:00<02:32,  4.20it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  2%|▏         | 2/128 [00:00<00:13,  9.29it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "  0%|          | 1/384 [00:00<00:51,  7.45it/s]/home/yangjiong/CategoryLearning/src/Bayesian_new/inference_engine/bayesian_engine.py:167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior /= np.sum(posterior)\n",
      "100%|██████████| 128/128 [00:02<00:00, 52.87it/s]\n",
      "100%|██████████| 128/128 [00:02<00:00, 51.43it/s]\n",
      "  4%|▎         | 26/704 [00:03<01:31,  7.38it/s]]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fitting_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/yangjiong/.conda/envs/bayes/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/yangjiong/.conda/envs/bayes/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/yangjiong/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/yangjiong/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_269713/352174695.py\", line 11, in process_subject\nNameError: name 'fitting_results' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     fitting_results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_fitting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mparallel_fitting\u001b[0;34m(learning_data, config, n_jobs)\u001b[0m\n\u001b[1;32m     19\u001b[0m subjects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(learning_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miSub\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 使用并行计算\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_subject\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43miSub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miSub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing Subjects\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 整理结果到字典\u001b[39;00m\n\u001b[1;32m     28\u001b[0m fitting_results \u001b[38;5;241m=\u001b[39m {res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miSub\u001b[39m\u001b[38;5;124m'\u001b[39m]: res \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results}\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/bayes/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fitting_results' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    fitting_results = parallel_fitting(learning_data, config_base, n_jobs=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存拟合结果\n",
    "result_path = Path(project_root) / 'results' / 'Bayesian'\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "filename = f'M_Base_fitting_results.joblib'\n",
    "joblib.dump(fitting_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型分析\n",
    "import src.Bayesian.utils.model_evaluation as model_eval\n",
    "importlib.reload(model_eval)\n",
    "from src.Bayesian.utils.model_evaluation import ModelEval\n",
    "\n",
    "model_eval = ModelEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载拟合结果\n",
    "fitting_results = joblib.load(result_path / 'M_Base_fitting_results.joblib')\n",
    "\n",
    "# 绘制最优参数变化图\n",
    "model_eval.plot_params_over_trials(fitting_results, 'beta', result_path / f'M_Base_beta.png')\n",
    "\n",
    "# 绘制k后验概率变化图\n",
    "model_eval.plot_posterior_probabilities(fitting_results, result_path / f'M_Base_posteriors.png')\n",
    "\n",
    "# 计算预测准确率\n",
    "predictive_results = {}\n",
    "for iSub, fit_result in fitting_results.items():\n",
    "    subject_data = learning_data[learning_data['iSub'] == iSub]\n",
    "    step_results = fit_result['step_results']\n",
    "    condition = fit_result['condition']\n",
    "    \n",
    "    predictions = model_eval.calculate_predictions(model_base, subject_data, step_results)\n",
    "    sliding_accuracy = model_eval.calculate_sliding_accuracy(predictions)\n",
    "    \n",
    "    predictive_results[iSub] = {\n",
    "        'condition': condition,\n",
    "        'step_results': step_results,\n",
    "        'predictions': predictions,\n",
    "        'sliding_accuracy': sliding_accuracy\n",
    "    }\n",
    "\n",
    "# 绘制预测准确率变化图\n",
    "filename = f'M_Base_predictive_accuracy.png'\n",
    "model_eval.plot_predictive_accuracy(predictive_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. + Forgetting ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "import src.Bayesian.M_fgt as model_forget\n",
    "importlib.reload(model_forget)\n",
    "from src.Bayesian.M_fgt import M_Fgt\n",
    "\n",
    "import src.Bayesian.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian.config import config_fgt\n",
    "model_forget = M_Fgt(config_fgt)\n",
    "\n",
    "model_forget.set_centers(all_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_results = {}\n",
    "for iSub, subject_data in learning_data.groupby('iSub'):\n",
    "    step_results = model_forget.fit_trial_by_trial(subject_data)\n",
    "    fitting_results[iSub] = {\n",
    "        'condition': subject_data['condition'].iloc[0],\n",
    "        'step_results': step_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存拟合结果\n",
    "result_path = Path(project_root) / 'results' / 'Bayesian'\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "filename = f'M_Fgt_fitting_results.joblib'\n",
    "joblib.dump(fitting_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载拟合结果\n",
    "fitting_results = joblib.load(result_path / 'M_Fgt_fitting_results.joblib')\n",
    "\n",
    "# 绘制后验概率变化图\n",
    "filename = f'M_Fgt_posteriors.png'\n",
    "model_eval.plot_posterior_probabilities(fitting_results, result_path / filename)\n",
    "\n",
    "# 计算预测准确率\n",
    "predictive_results = {}\n",
    "for iSub, fit_result in fitting_results.items():\n",
    "    try:\n",
    "        subject_data = learning_data[learning_data['iSub'] == iSub]\n",
    "        step_results = fit_result['step_results']\n",
    "        condition = fit_result['condition']\n",
    "        \n",
    "        predictions = model_eval.calculate_predictions(model_forget, subject_data, step_results)\n",
    "        sliding_accuracy = model_eval.calculate_sliding_accuracy(predictions)\n",
    "        \n",
    "        predictive_results[iSub] = {\n",
    "            'condition': condition,\n",
    "            'step_results': step_results,\n",
    "            'predictions': predictions,\n",
    "            'sliding_accuracy': sliding_accuracy\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing predictions for subject {iSub}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# 绘制预测准确率变化图\n",
    "filename = f'M_Fgt_predictive_accuracy.png'\n",
    "model_eval.plot_predictive_accuracy(predictive_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. + Decision Noise ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "import src.Bayesian.M_dec as model_decision\n",
    "importlib.reload(model_decision)\n",
    "from src.Bayesian.M_dec import M_Dec\n",
    "\n",
    "import src.Bayesian.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian.config import config_dec\n",
    "model_decision = M_Dec(config_dec)\n",
    "\n",
    "model_decision.set_centers(all_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型拟合\n",
    "fitting_results = {}\n",
    "for iSub, subject_data in learning_data.groupby('iSub'):\n",
    "    step_results = model_decision.fit_trial_by_trial(subject_data)\n",
    "    fitting_results[iSub] = {\n",
    "        'condition': subject_data['condition'].iloc[0],\n",
    "        'step_results': step_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存拟合结果\n",
    "result_path = Path(project_root) / 'results' / 'Bayesian'\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "filename = f'M_Dec_fitting_results.joblib'\n",
    "joblib.dump(fitting_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载拟合结果\n",
    "fitting_results = joblib.load(result_path / 'M_Dec_fitting_results.joblib')\n",
    "\n",
    "# 绘制最优参数变化图\n",
    "model_eval.plot_params_over_trials(fitting_results, 'beta', result_path / f'M_Dec_beta.png')\n",
    "model_eval.plot_params_over_trials(fitting_results, 'phi', result_path / f'M_Dec_phi.png')\n",
    "\n",
    "# 绘制k的后验概率变化图\n",
    "model_eval.plot_posterior_probabilities(fitting_results, result_path / f'M_Dec_posteriors.png')\n",
    "\n",
    "# 计算预测准确率\n",
    "predictive_results = {}\n",
    "for iSub, fit_result in fitting_results.items():\n",
    "    try:\n",
    "        subject_data = learning_data[learning_data['iSub'] == iSub]\n",
    "        step_results = fit_result['step_results']\n",
    "        condition = fit_result['condition']\n",
    "        \n",
    "        predictions = model_eval.calculate_predictions(model_decision, subject_data, step_results)\n",
    "        sliding_accuracy = model_eval.calculate_sliding_accuracy(predictions)\n",
    "        \n",
    "        predictive_results[iSub] = {\n",
    "            'condition': condition,\n",
    "            'step_results': step_results,\n",
    "            'predictions': predictions,\n",
    "            'sliding_accuracy': sliding_accuracy\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing predictions for subject {iSub}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# 绘制预测准确率变化图\n",
    "filename = f'M_Dec_predictive_accuracy.png'\n",
    "model_eval.plot_predictive_accuracy(predictive_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. + Perceptive Noise ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data = pd.read_csv(processed_path / 'Task2_processed_perceived.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入基线模型\n",
    "import src.Bayesian.M_base as model_base\n",
    "importlib.reload(model_base)\n",
    "from src.Bayesian.M_base import M_Base\n",
    "\n",
    "import src.Bayesian.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian.config import config_base\n",
    "model_base = M_Base(config_base)\n",
    "\n",
    "model_base.set_centers(all_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型拟合\n",
    "fitting_results = {}\n",
    "for iSub, subject_data in learning_data.groupby('iSub'):\n",
    "    step_results = model_base.fit_trial_by_trial(subject_data)\n",
    "    fitting_results[iSub] = {\n",
    "        'condition': subject_data['condition'].iloc[0],\n",
    "        'step_results': step_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存拟合结果\n",
    "result_path = Path(project_root) / 'results' / 'Bayesian'\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "filename = f'M_Perc_fitting_results.joblib'\n",
    "joblib.dump(fitting_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载拟合结果\n",
    "fitting_results = joblib.load(result_path / 'M_Perc_fitting_results.joblib')\n",
    "\n",
    "# 绘制最优参数变化图\n",
    "model_eval.plot_params_over_trials(fitting_results, 'beta', result_path / f'M_Perc_beta.png')\n",
    "\n",
    "# 绘制k后验概率变化图\n",
    "model_eval.plot_posterior_probabilities(fitting_results, result_path / f'M_Perc_posteriors.png')\n",
    "\n",
    "# 计算预测准确率\n",
    "predictive_results = {}\n",
    "for iSub, fit_result in fitting_results.items():\n",
    "    subject_data = learning_data[learning_data['iSub'] == iSub]\n",
    "    step_results = fit_result['step_results']\n",
    "    condition = fit_result['condition']\n",
    "    \n",
    "    predictions = model_eval.calculate_predictions(model_base, subject_data, step_results)\n",
    "    sliding_accuracy = model_eval.calculate_sliding_accuracy(predictions)\n",
    "    \n",
    "    predictive_results[iSub] = {\n",
    "        'condition': condition,\n",
    "        'step_results': step_results,\n",
    "        'predictions': predictions,\n",
    "        'sliding_accuracy': sliding_accuracy\n",
    "    }\n",
    "\n",
    "# 绘制预测准确率变化图\n",
    "filename = f'M_Perc_predictive_accuracy.png'\n",
    "model_eval.plot_predictive_accuracy(predictive_results, result_path / filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. + Attention Weight ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入基线模型\n",
    "import src.Bayesian.M_base as model_base\n",
    "importlib.reload(model_base)\n",
    "from src.Bayesian.M_base import M_Base\n",
    "\n",
    "import src.Bayesian.config as config\n",
    "importlib.reload(config)\n",
    "from src.Bayesian.config import config_base\n",
    "model_base = M_Base(config_base)\n",
    "\n",
    "model_base.set_centers(all_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Full ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
