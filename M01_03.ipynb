{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partition rules\n",
    "def partition(condition):\n",
    "    if condition == 1:\n",
    "        # 单超平面分割，4种情况\n",
    "        return [(i,) for i in range(4)]\n",
    "    else:\n",
    "        # 两个超平面分割，6种情况\n",
    "        two_planes = list(itertools.combinations(range(4), 2))\n",
    "        \n",
    "        # 三个超平面分割，24种情况\n",
    "        three_planes = []\n",
    "        for m in range(4):\n",
    "            other_dims = [i for i in range(4) if i != m]\n",
    "            for n1, n2 in itertools.combinations(other_dims, 2):\n",
    "                three_planes.append((m, n1, n2))\n",
    "                three_planes.append((m, n2, n1))\n",
    "        \n",
    "        return two_planes + three_planes\n",
    "\n",
    "# generate centers\n",
    "def generate_centers():\n",
    "    centers = {}\n",
    "    \n",
    "    # 条件1的中心点\n",
    "    for rule in partition(1):\n",
    "        dim = rule[0]\n",
    "        centers[rule] = ([0.25 if i == dim else 0.5 for i in range(4)],\n",
    "                         [0.75 if i == dim else 0.5 for i in range(4)])\n",
    "    \n",
    "    # 条件2的中心点\n",
    "    for rule in partition(2):\n",
    "        if len(rule) == 2:  # 两个超平面\n",
    "            dim1, dim2 = rule\n",
    "            centers[rule] = tuple([0.25 + 0.5*i if d in rule else 0.5 for d in range(4)]\n",
    "                                  for i in range(2) for j in range(2))\n",
    "        else:  # 三个超平面\n",
    "            m, n1, n2 = rule\n",
    "            centers[rule] = (\n",
    "                [0.25 if d == m else (0.25 if d == n1 else 0.5) for d in range(4)],\n",
    "                [0.25 if d == m else (0.75 if d == n1 else 0.5) for d in range(4)],\n",
    "                [0.75 if d == m else (0.25 if d == n2 else 0.5) for d in range(4)],\n",
    "                [0.75 if d == m else (0.75 if d == n2 else 0.5) for d in range(4)]\n",
    "            )\n",
    "    \n",
    "    return centers\n",
    "\n",
    "# generate all possible centers\n",
    "all_centers = generate_centers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "class ModelParams:\n",
    "    def __init__(self, k, beta):\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "\n",
    "# get conters depending on k and condition\n",
    "def get_centers(k, condition):\n",
    "    rules = partition(condition)\n",
    "    if 1 <= k <= len(rules):\n",
    "        return all_centers[rules[k-1]]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid k for condition {condition}. Must be between 1 and {len(rules)}.\")\n",
    "\n",
    "# define likelihood\n",
    "def likelihood(params, data, condition):\n",
    "    k, beta = params.k, params.beta\n",
    "    \n",
    "    x = data[['feature1', 'feature2', 'feature3', 'feature4']].values\n",
    "    c = data['choice'].values\n",
    "    r = data['feedback'].values\n",
    "\n",
    "    # calculate distances between x and centers\n",
    "    centers = get_centers(k, condition)\n",
    "    distances = np.array([np.linalg.norm(x - np.array(center), axis=1) for center in centers])\n",
    "\n",
    "    # calculate choosing probablity\n",
    "    probs = np.exp(-beta * distances)\n",
    "    probs /= np.sum(probs, axis=0, keepdims=True)\n",
    "    p_c = probs[c - 1, np.arange(len(c))]\n",
    "    \n",
    "    return np.where(r == 1, p_c, 1 - p_c)\n",
    "\n",
    "# define prior\n",
    "def prior(params, condition):\n",
    "    max_k = len(partition(condition))\n",
    "    k_prior = 1/max_k if 1 <= params.k <= max_k else 0\n",
    "    beta_prior = np.exp(-params.beta) if params.beta > 0 else 0\n",
    "    return k_prior * beta_prior\n",
    "\n",
    "# define posterior\n",
    "def posterior(params, data, condition):\n",
    "    prior_value = prior(params, condition)\n",
    "    log_prior = np.log(prior_value) if prior_value > 0 else -np.inf\n",
    "    log_likelihood = np.sum(np.log(likelihood(params, data, condition)))\n",
    "    return -(log_prior + log_likelihood)  # negative log posterior\n",
    "\n",
    "# New function to predict choice\n",
    "def predict_choice(params, x, condition):\n",
    "    k, beta = params.k, params.beta\n",
    "    centers = get_centers(k, condition)\n",
    "    distances = np.array([np.linalg.norm(x - np.array(center)) for center in centers])\n",
    "    probs = np.exp(-beta * distances)\n",
    "    probs /= np.sum(probs)\n",
    "    return np.argmax(probs) + 1  # +1 because choices are 1-indexed\n",
    "\n",
    "# fit model\n",
    "def fit_model(data):\n",
    "    condition = data['condition'].iloc[0]\n",
    "    max_k = len(partition(condition))\n",
    "    \n",
    "    best_params = None  # 最佳的k和beta参数\n",
    "    best_posterior = -np.inf  # 最佳参数对应的后验概率\n",
    "    k_posteriors = {}  # 每个k值的边缘后验概率\n",
    "    \n",
    "    for k in range(1, max_k + 1):\n",
    "        initial_beta = 1\n",
    "        result = minimize(\n",
    "            lambda beta: posterior(ModelParams(k, beta[0]), data, condition),\n",
    "            [initial_beta],\n",
    "            bounds=[(0, 30)]\n",
    "        )\n",
    "           \n",
    "        beta_opt = result.x[0]\n",
    "        posterior_opt = -result.fun\n",
    "        k_posteriors[k] = posterior_opt\n",
    "\n",
    "        if posterior_opt > best_posterior:\n",
    "            best_posterior = posterior_opt\n",
    "            best_params = ModelParams(k=k, beta=beta_opt)\n",
    "    \n",
    "    # Normalize log probabilities\n",
    "    max_log_posterior = max(k_posteriors.values())\n",
    "    k_posteriors = {k: np.exp(log_p - max_log_posterior) for k, log_p in k_posteriors.items()}\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    total = sum(k_posteriors.values())\n",
    "    k_posteriors = {k: p / total for k, p in k_posteriors.items()}\n",
    "    \n",
    "    return best_params, best_posterior, k_posteriors\n",
    "\n",
    "# fit model trial by trial\n",
    "def fit_model_for_steps(data):\n",
    "    num_trials = len(data)\n",
    "    step_results = []\n",
    "    predictions = []\n",
    "    cumulative_accuracy = []\n",
    "    correct_count = 0\n",
    "    \n",
    "    for step in range(1, num_trials):\n",
    "        trial_data = data.iloc[:step]\n",
    "        fitted_params, best_posterior, k_posteriors = fit_model(trial_data)\n",
    "        step_results.append({\n",
    "            'k': fitted_params.k,\n",
    "            'beta': fitted_params.beta,\n",
    "            'best_posterior': best_posterior,\n",
    "            'k_posteriors': k_posteriors\n",
    "        })\n",
    "        \n",
    "        # Predict next trial\n",
    "        next_trial = data.iloc[step]\n",
    "        x = next_trial[['feature1', 'feature2', 'feature3', 'feature4']].values\n",
    "        predicted_choice = predict_choice(fitted_params, x, data['condition'].iloc[0])\n",
    "        actual_choice = next_trial['choice']\n",
    "        correct = predicted_choice == actual_choice\n",
    "        correct_count += correct\n",
    "        accuracy = correct_count / (step + 1)\n",
    "        \n",
    "        predictions.append({\n",
    "            'trial': step + 1,\n",
    "            'predicted_choice': predicted_choice,\n",
    "            'actual_choice': actual_choice,\n",
    "            'correct': correct\n",
    "        })\n",
    "        cumulative_accuracy.append(accuracy)\n",
    "    \n",
    "    return step_results, predictions, cumulative_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "data = pd.read_csv('Task2.csv')\n",
    "\n",
    "# fit model by subjects\n",
    "results = {}\n",
    "for iSub, subject_data in data.groupby('iSub'):\n",
    "    try:\n",
    "        step_results, predictions, cumulative_accuracy = fit_model_for_steps(subject_data)\n",
    "        condition = subject_data['condition'].iloc[0]\n",
    "        results[iSub] = {\n",
    "            'step_results': step_results, \n",
    "            'predictions': predictions,\n",
    "            'cumulative_accuracy': cumulative_accuracy,\n",
    "            'condition': condition\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting model for subject {iSub}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1:\n",
      "  Final Fitted k: 1\n",
      "  Final Fitted beta: 14.5905\n",
      "  Final log posterior: -29.6859\n",
      "\n",
      "Subject 4:\n",
      "  Final Fitted k: 1\n",
      "  Final Fitted beta: 15.8896\n",
      "  Final log posterior: -30.2270\n",
      "\n",
      "Subject 6:\n",
      "  Final Fitted k: 7\n",
      "  Final Fitted beta: 18.8805\n",
      "  Final log posterior: -53.7345\n",
      "\n",
      "Subject 11:\n",
      "  Final Fitted k: 7\n",
      "  Final Fitted beta: 20.4112\n",
      "  Final log posterior: -47.6261\n",
      "\n",
      "Subject 21:\n",
      "  Final Fitted k: 7\n",
      "  Final Fitted beta: 25.9062\n",
      "  Final log posterior: -92.9252\n",
      "\n",
      "Subject 26:\n",
      "  Final Fitted k: 7\n",
      "  Final Fitted beta: 23.3889\n",
      "  Final log posterior: -45.9550\n",
      "\n",
      "Subject 27:\n",
      "  Final Fitted k: 7\n",
      "  Final Fitted beta: 28.9036\n",
      "  Final log posterior: -71.3852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print final fitted parameters\n",
    "for iSub, subject_info in results.items():\n",
    "    step_results = subject_info['step_results']\n",
    "    final_result = step_results[-1]\n",
    "    print(f\"Subject {iSub}:\")\n",
    "    print(f\"  Final Fitted k: {final_result['k']}\")\n",
    "    print(f\"  Final Fitted beta: {final_result['beta']:.4f}\")\n",
    "    print(f\"  Final log posterior: {final_result['best_posterior']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot parameters over trials\n",
    "def plot_params_over_trials(step_results, iSub):\n",
    "    num_steps = len(step_results)\n",
    "    k_values = [result['k'] for result in step_results]\n",
    "    beta_values = [result['beta'] for result in step_results]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Plot k values\n",
    "    ax1.plot(range(1, num_steps + 1), k_values, marker='o')\n",
    "    ax1.set_title(f'Subject {iSub} - k value over trials')\n",
    "    ax1.set_xlabel('Number of trials')\n",
    "    ax1.set_ylabel('k value')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot beta values\n",
    "    ax2.plot(range(1, num_steps + 1), beta_values, marker='o')\n",
    "    ax2.set_title(f'Subject {iSub} - beta value over trials')\n",
    "    ax2.set_xlabel('Number of trials')\n",
    "    ax2.set_ylabel('beta value')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'M0103_params_over_trials_subject_{iSub}_.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_posterior_probabilities(step_results, condition, iSub):\n",
    "    num_steps = len(step_results)\n",
    "    max_k = max(k for result in step_results for k in result['k_posteriors'].keys())\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    k_posteriors = {k: np.zeros(num_steps) for k in range(1, max_k + 1)}\n",
    "\n",
    "    for step, result in enumerate(step_results):\n",
    "        for k in range(1, max_k + 1):\n",
    "            k_posteriors[k][step] = result['k_posteriors'].get(k, 0)\n",
    "\n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.suptitle(f'Posterior Probabilities for k (Subject {iSub}, Condition {condition})', fontsize=16)\n",
    "\n",
    "    # Plot k posteriors\n",
    "    for k in range(1, max_k + 1):\n",
    "        if (condition == 1 and k == 1) or (condition != 1 and k == 7):\n",
    "            ax.plot(range(1, num_steps + 1), k_posteriors[k], label=f'k={k}', linewidth=3, color='red')\n",
    "        else:\n",
    "            ax.plot(range(1, num_steps + 1), k_posteriors[k], label=f'k={k}')\n",
    "    \n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('Posterior Probability')\n",
    "    ax.set_title('Posterior Probabilities for k')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'M0103_posteriors_subject_{iSub}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iSub, subject_info in results.items():\n",
    "    step_results = subject_info['step_results']\n",
    "    condition = subject_info['condition']\n",
    "    plot_params_over_trials(step_results, iSub)\n",
    "    plot_posterior_probabilities(step_results, condition, iSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative accuracy for each subject\n",
    "plt.figure(figsize=(12, 8))\n",
    "for iSub, result in results.items():\n",
    "    plt.plot(range(2, len(result['cumulative_accuracy']) + 2), result['cumulative_accuracy'], label=f'Subject {iSub}')\n",
    "\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Cumulative Prediction Accuracy')\n",
    "plt.title('Prediction Accuracy Over Trials')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('M0103_prediction_accuracy.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
