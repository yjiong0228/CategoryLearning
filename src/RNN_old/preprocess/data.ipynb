{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "sub_dict = {}\n",
    "with CLDataset.get_reader('dataset/Task2.csv') as reader:\n",
    "    for row in reader:\n",
    "        if row['iSub'] not in sub_dict:\n",
    "            sub_dict[row['iSub']] = {}\n",
    "            sub_dict[row['iSub']]['index'] = row['iSub']\n",
    "            sub_dict[row['iSub']]['session'] = row['iSession']\n",
    "            sub_dict[row['iSub']]['version'] = row['version']\n",
    "            sub_dict[row['iSub']]['condition'] = row['condition']\n",
    "            sub_dict[row['iSub']]['exp'] = []\n",
    "        exp_list = sub_dict[row['iSub']]['exp']\n",
    "        trial = row['iTrial']\n",
    "        feature = [row['feature1'], row['feature2'], row['feature3'], row['feature4']]\n",
    "        text = row['text']        \n",
    "        category = row['category']\n",
    "        choice = row['choice']\n",
    "        feadback = row['feedback']\n",
    "        exp_list.append({'trial': trial, 'feature': feature, 'text': text, 'category': category, 'choice': choice, 'feedback': feadback})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CLDataset\n",
    "sub_dict = CLDataset.get_sub_dict('dataset/Task2.csv')\n",
    "sub_dict = {k: v for k, v in sub_dict.items() if v['version'] != '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('dataset/Task2.csv', encoding=\"GBK\", errors=\"ignore\", mode=\"r\", newline=\"\")\n",
    "reader = csv.DictReader(f)\n",
    "reader.fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import numpy as np\n",
    "waveform, sample_rate = torchaudio.load('Recording/9_1/128.wav')\n",
    "waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "\n",
    "audio = waveform.squeeze().numpy()\n",
    "\n",
    "import whisper\n",
    "# 加载Whisper预训练模型\n",
    "model = whisper.load_model(\"turbo\")\n",
    "\n",
    "result = model.transcribe(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile('Recording/9_1/128.wav') as source:\n",
    "    audio = r.record(source)\n",
    "result = r.recognize_google_cloud(audio)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "recording_dir = glob.glob('Recording/*')\n",
    "recording_dir.sort(key=lambda x: (int(x.split('/')[-1].split('_')[0]), int(x.split('/')[-1].split('_')[1].split('.')[0])))\n",
    "recording_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "recording_dir = glob.glob('Recording/*')\n",
    "recording_dir = [x for x in recording_dir if x.split('/')[-1].split('_')[0] in ['8', '13', '15', '19', '20', '21']]\n",
    "recording_dir.sort(key=lambda x: (int(x.split('/')[-1].split('_')[0]), int(x.split('/')[-1].split('_')[1].split('.')[0])))\n",
    "recording_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "remote_base_dir = 'gpu6/categoryLearning/'\n",
    "for dir in recording_dir:\n",
    "    remote_dir = remote_base_dir+dir\n",
    "    files = glob.glob(dir+'/*')\n",
    "    print(files)\n",
    "    print(remote_dir)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset/Task2.csv', encoding='GBK')\n",
    "texts = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_xlsx = pd.read_excel('dataset/1_1.xlsx')\n",
    "texts = df_xlsx['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "# model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "vectors = outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# 使用DBSCAN进行聚类\n",
    "dbscan = DBSCAN(eps=2, min_samples=2)\n",
    "dbscan_clusters = dbscan.fit_predict(vectors.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.DataFrame({'cluster': dbscan_clusters, 'text': texts})\n",
    "df_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters[df_clusters['cluster'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "KMeans_model = KMeans(n_clusters=2, random_state=0)\n",
    "KMeans_clusters = KMeans_model.fit_predict(vectors.detach().numpy()[65:96,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.DataFrame({'cluster': KMeans_clusters, 'text': texts[65:96]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_xlsx = pd.read_excel('dataset/1_1.xlsx')\n",
    "texts = df_xlsx['text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [inputs['input_ids'][i:i+10] for i in range(0, len(inputs['input_ids'])-10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, input_ids):\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx]\n",
    "\n",
    "dataset = TextDataset(input_ids)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataloader:\n",
    "\n",
    "    print(x.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(58, 128, 2, 58)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(x, dim=-1)[:,1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.functional.cross_entropy(out.reshape(-1, 58), torch.argmax(x, dim=-1)[:,1:].reshape(-1), ignore_index=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading texts: 100%|██████████| 2/2 [00:00<00:00, 620.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sub_train_id = [2 , 3]\n",
    "\n",
    "df = pd.read_csv('/workspace/category-learning/recording_finish.csv', keep_default_na=False)\n",
    "texts = []\n",
    "for sub_id in tqdm(sub_train_id, desc='Loading texts'):\n",
    "    text = df[df['iSub'] == sub_id]['text'].tolist()\n",
    "    texts.append(text)\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "toks = []\n",
    "for text in texts:\n",
    "    tok = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    toks.append(tok)\n",
    "# max_length = max(tok['input_ids'].shape[1] for tok in toks)\n",
    "\n",
    "# padded_toks = []\n",
    "# for tok in toks:\n",
    "#     input_ids = torch.nn.functional.pad(tok['input_ids'], (0, max_length - tok['input_ids'].shape[1]), value=tokenizer.pad_token_id)\n",
    "#     attention_mask = torch.nn.functional.pad(tok['attention_mask'], (0, max_length - tok['attention_mask'].shape[1]), value=0)\n",
    "#     padded_toks.append({'input_ids': input_ids, 'attention_mask': attention_mask})\n",
    "\n",
    "# model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "# model.eval()\n",
    "# for tok in padded_toks:\n",
    "#     inputs = {k: v.unsqueeze(0) for k, v in tok.items()}\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "#     vectors = outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "all_text_vector = model(**toks[0]).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150201/4117357251.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_tok = torch.load('/workspace/category-learning/all_tok.pt')\n",
      "/tmp/ipykernel_150201/4117357251.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_choice = torch.load('/workspace/category-learning/all_choice.pt')\n",
      "/tmp/ipykernel_150201/4117357251.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_feedback = torch.load('/workspace/category-learning/all_feedback.pt')\n",
      "/tmp/ipykernel_150201/4117357251.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sub_exp_start = torch.load('/workspace/category-learning/sub_exp_start.pt')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "all_tok = torch.load('/workspace/category-learning/all_tok.pt')\n",
    "all_choice = torch.load('/workspace/category-learning/all_choice.pt')\n",
    "all_feedback = torch.load('/workspace/category-learning/all_feedback.pt')\n",
    "sub_exp_start = torch.load('/workspace/category-learning/sub_exp_start.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CategoryDataset(Dataset):\n",
    "    def __init__(self, text, choice, feedback, sub_exp_start):\n",
    "        self.all_data = []\n",
    "        for i in range(len(sub_exp_start)-1):\n",
    "            start = sub_exp_start[i]\n",
    "            end = sub_exp_start[i+1]\n",
    "            for j in range(start, end-11):\n",
    "                self.all_data.append((torch.stack([text[k] for k in range(j, j+10)]),\n",
    "                                      torch.stack([choice[k] for k in range(j, j+10)]),\n",
    "                                      torch.stack([feedback[k] for k in range(j, j+10)])))\n",
    "                                      \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.all_data[idx]\n",
    "    \n",
    "dataset = CategoryDataset(all_tok, all_choice, all_feedback, sub_exp_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/category/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rnn.core import CategoryRNN\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = CategoryRNN(len(tokenizer.get_vocab()), 768, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4727, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cal_loss(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 101, 7531, 4764, 5556, 2094, 4764,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1928, 7270, 5597, 4764,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5556, 2094, 7270, 1928, 4764,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1928, 4764, 5556, 2094, 4764,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 7531, 4764, 5556, 2094, 4764,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1928, 4764, 5556, 2094, 4764,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1928, 7270, 5597, 7270,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5556, 2094, 7270, 1928, 4764,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1928, 4764, 5556, 2094, 4764,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 5556, 2094, 7270,  117, 1928, 7270,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0]]), tensor([0, 2, 1, 0, 0, 0, 3, 1, 0, 1]), tensor([1, 0, 1, 1, 1, 1, 1, 0, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def collate_fn(batch):\n",
    "    return batch\n",
    "for data in DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn):\n",
    "    print(data[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 繁体转简体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '/workspace/category-learning/recording-1217.csv'\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_file, encoding='utf', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/category/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Converting text:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting text: 100%|██████████| 313/313 [00:00<00:00, 3320.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import opencc\n",
    "from tqdm.auto import tqdm\n",
    "converter = opencc.OpenCC('t2s')\n",
    "for i in tqdm(range(len(df)), desc='Converting text'):\n",
    "    text = df.loc[i, 'text']\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    text = text.replace(' ', '').strip('\"')\n",
    "    df.loc[i, 'text'] = converter.convert(df.loc[i, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/workspace/category-learning/recording-1217.csv', index=False, encoding='utf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../recording-1217.csv', encoding='utf')\n",
    "for i in range(len(df)):\n",
    "    text = str(df.loc[i, 'text']).rstrip('\"').lstrip('\"')\n",
    "    df.loc[i, 'text'] = f'{text}'\n",
    "    # if '\"' not in text:\n",
    "    #     df.loc[i, 'text'] = f'\"{text}\"'\n",
    "df.to_csv('/workspace/category-learning/recording-1217.csv', index=False, encoding='utf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_id, group in df.groupby('iSub'):\n",
    "    if sub_id == 17:\n",
    "        continue\n",
    "    group.to_csv(f'../Task2_{sub_id}_aud.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "aud_files = glob.glob('../dataset/aud/Task2_*_aud.csv')\n",
    "aud_files = sorted(aud_files, key=lambda x: int(x.split('_')[1]))\n",
    "df = pd.DataFrame()\n",
    "for aud_file in aud_files:\n",
    "    try:\n",
    "        df_ = pd.read_csv(aud_file, encoding='utf-8')\n",
    "    except:\n",
    "        df_ = pd.read_csv(aud_file, encoding='GBK')\n",
    "    df = pd.concat([df, df_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  7,  8,  9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24,\n",
       "       25])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['iSub'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dataset/Task2_aud.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "category",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
