{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e61af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 阶段 2/3: 模型模拟 ===\n",
      "正在生成模拟数据...\n",
      "模拟结束，详细数据已打包保存至: simulation_results.pkl\n",
      "\n",
      "=== 阶段 3/3: 结果绘图 ===\n",
      "正在加载模拟数据...\n",
      "正在生成 Accuracy 汇总图...\n",
      "所有绘图工作完成！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import pickle  # 用于保存复杂的 simulation 结果 (如 cluster 历史)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ==========================================\n",
    "# 1. 模型定义 (保持不变)\n",
    "# ==========================================\n",
    "\n",
    "class RationalModelSystem2:\n",
    "    def __init__(self, D, alpha, sigma, l0):\n",
    "        self.D = D\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.l0 = l0\n",
    "        self.clusters = [] \n",
    "        self.total_N = 0\n",
    "        self.history = [] \n",
    "\n",
    "    def _gaussian_likelihood(self, x, cluster):\n",
    "        mu = cluster['sum_x'] / cluster['N']\n",
    "        prefactor = (1.0 / (np.sqrt(2 * np.pi) * self.sigma)) ** self.D\n",
    "        dist_sq = np.sum((x - mu) ** 2)\n",
    "        exponent = np.exp(-dist_sq / (2 * self.sigma ** 2))\n",
    "        return prefactor * exponent\n",
    "\n",
    "    def get_posteriors(self, x):\n",
    "        priors = []\n",
    "        likelihoods = []\n",
    "        for cluster in self.clusters:\n",
    "            prior = cluster['N'] / (self.total_N + self.alpha)\n",
    "            priors.append(prior)\n",
    "            lik = self._gaussian_likelihood(x, cluster)\n",
    "            likelihoods.append(lik)\n",
    "        priors.append(self.alpha / (self.total_N + self.alpha))\n",
    "        likelihoods.append(self.l0)\n",
    "        unnormalized = np.array(priors) * np.array(likelihoods)\n",
    "        if np.sum(unnormalized) == 0:\n",
    "            return np.ones(len(unnormalized)) / len(unnormalized)\n",
    "        return unnormalized / np.sum(unnormalized)\n",
    "\n",
    "    def get_choice_probs(self, x):\n",
    "        if self.total_N == 0:\n",
    "            return {1: 0.5, 2: 0.5}\n",
    "        posteriors = self.get_posteriors(x)\n",
    "        prob_y = {1: 0.0, 2: 0.0}\n",
    "        for k, cluster in enumerate(self.clusters):\n",
    "            w_k = posteriors[k]\n",
    "            n_1 = cluster['y_counts'].get(1, 0)\n",
    "            n_2 = cluster['y_counts'].get(2, 0)\n",
    "            p_1_k = (n_1 + 1) / (cluster['N'] + 2)\n",
    "            p_2_k = (n_2 + 1) / (cluster['N'] + 2)\n",
    "            prob_y[1] += w_k * p_1_k\n",
    "            prob_y[2] += w_k * p_2_k\n",
    "        w_new = posteriors[-1]\n",
    "        prob_y[1] += w_new * 0.5\n",
    "        prob_y[2] += w_new * 0.5\n",
    "        return prob_y\n",
    "\n",
    "    def update(self, x, y):\n",
    "        self._record_history()\n",
    "        if self.total_N == 0:\n",
    "            self._create_new_cluster(x, y)\n",
    "        else:\n",
    "            posteriors = self.get_posteriors(x)\n",
    "            winner_idx = np.argmax(posteriors)\n",
    "            if winner_idx == len(self.clusters):\n",
    "                self._create_new_cluster(x, y)\n",
    "            else:\n",
    "                self._update_cluster(winner_idx, x, y)\n",
    "        self.total_N += 1\n",
    "\n",
    "    def _create_new_cluster(self, x, y):\n",
    "        new_cluster = {'N': 1, 'sum_x': x.copy(), 'y_counts': {1: 0, 2: 0}}\n",
    "        new_cluster['y_counts'][y] = 1\n",
    "        self.clusters.append(new_cluster)\n",
    "\n",
    "    def _update_cluster(self, idx, x, y):\n",
    "        cluster = self.clusters[idx]\n",
    "        cluster['N'] += 1\n",
    "        cluster['sum_x'] += x\n",
    "        cluster['y_counts'][y] = cluster['y_counts'].get(y, 0) + 1\n",
    "\n",
    "    def _record_history(self):\n",
    "        snapshot = []\n",
    "        for c in self.clusters:\n",
    "            mu = c['sum_x'] / c['N']\n",
    "            snapshot.append(mu.copy())\n",
    "        self.history.append(snapshot)\n",
    "\n",
    "def neg_log_likelihood(params, df_sub):\n",
    "    alpha, sigma, l0 = params\n",
    "    if sigma <= 1e-4 or alpha <= 1e-4 or l0 <= 1e-6: return 1e10\n",
    "    model = RationalModelSystem2(4, alpha, sigma, l0)\n",
    "    nll = 0.0\n",
    "    for _, row in df_sub.iterrows():\n",
    "        x = np.array([row['feature1'], row['feature2'], row['feature3'], row['feature4']])\n",
    "        choice = row['choice'] \n",
    "        probs = model.get_choice_probs(x)\n",
    "        p_choice = max(probs[choice], 1e-6)\n",
    "        nll -= np.log(p_choice)\n",
    "        true_cat = row['category']\n",
    "        model.update(x, true_cat)\n",
    "    return nll\n",
    "\n",
    "# ==========================================\n",
    "# 2. 模块 A: 拟合 (Fitting)\n",
    "# ==========================================\n",
    "\n",
    "def fit_single_subject(sub_id, sub_df):\n",
    "    \"\"\"只负责拟合参数\"\"\"\n",
    "    print(f\"[Fit] Sub {sub_id} 正在拟合...\")\n",
    "    initial_params = [1.0, 0.15, 0.001]\n",
    "    bounds = [(0.01, 5.0), (0.01, 0.5), (1e-6, 0.05)]\n",
    "    \n",
    "    try:\n",
    "        res = minimize(neg_log_likelihood, initial_params, args=(sub_df,), \n",
    "                       bounds=bounds, method='L-BFGS-B')\n",
    "        return {\n",
    "            'iSub': sub_id,\n",
    "            'alpha': res.x[0],\n",
    "            'sigma': res.x[1],\n",
    "            'l0': res.x[2],\n",
    "            'nll': res.fun\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"[Fit] Sub {sub_id} 失败: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_fitting(data_path, output_param_file):\n",
    "    print(f\"\\n=== 阶段 1/3: 参数拟合 ===\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    sub_ids = df['iSub'].unique()\n",
    "    \n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(fit_single_subject)(sub_id, df[df['iSub'] == sub_id].copy().reset_index(drop=True))\n",
    "        for sub_id in sub_ids\n",
    "    )\n",
    "    \n",
    "    params_df = pd.DataFrame([r for r in results if r is not None])\n",
    "    params_df.sort_values('iSub', inplace=True)\n",
    "    params_df.to_csv(output_param_file, index=False)\n",
    "    print(f\"拟合完成，参数已保存至: {output_param_file}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. 模块 B: 模拟 (Simulation)\n",
    "# ==========================================\n",
    "\n",
    "def simulate_subject(sub_id, sub_df, params):\n",
    "    \"\"\"\n",
    "    运行模型，生成并返回所有需要保存的详细数据。\n",
    "    这里不画图，只产生数据。\n",
    "    \"\"\"\n",
    "    alpha, sigma, l0 = params['alpha'], params['sigma'], params['l0']\n",
    "    model = RationalModelSystem2(4, alpha, sigma, l0)\n",
    "    \n",
    "    # 用于保存每一试次的标量数据\n",
    "    trial_data = []\n",
    "    \n",
    "    for i, row in sub_df.iterrows():\n",
    "        x = np.array([row['feature1'], row['feature2'], row['feature3'], row['feature4']])\n",
    "        true_cat = row['category']  # 1 或 2\n",
    "        choice = row['choice']      # 1 或 2\n",
    "        \n",
    "        # 1. 获取模型预测概率\n",
    "        probs = model.get_choice_probs(x)\n",
    "        \n",
    "        # 2. 核心：计算模型对【真实类别】的预测概率\n",
    "        # 如果 true_cat 是 1，取 probs[1]；如果是 2，取 probs[2]\n",
    "        prob_of_correct_cat = probs.get(true_cat, 0.0)\n",
    "        \n",
    "        # 3. 记录被试行为 (0:错误, 1:正确)\n",
    "        human_is_correct = 1 if choice == true_cat else 0\n",
    "        \n",
    "        # 4. 记录熵\n",
    "        entropy = -sum(p*np.log2(p+1e-9) for p in probs.values())\n",
    "        \n",
    "        trial_data.append({\n",
    "            'trial': i+1,\n",
    "            'prob_correct': prob_of_correct_cat, # 模型预测正确类别的概率\n",
    "            'human_correct': human_is_correct,   # 被试是否正确\n",
    "            'num_clusters': len(model.clusters), # 当前 Cluster 数量\n",
    "            'entropy': entropy                   # 熵\n",
    "        })\n",
    "        \n",
    "        # 5. 更新模型\n",
    "        model.update(x, true_cat)\n",
    "        \n",
    "    model._record_history() # 记录最后状态用于画 Cluster 轨迹\n",
    "    \n",
    "    return {\n",
    "        'iSub': sub_id,\n",
    "        'trial_df': pd.DataFrame(trial_data), # 标量数据 (用于画 Accuracy, Entropy, N_Clusters)\n",
    "        'cluster_history': model.history      # 复杂数据 (用于画 Dim Evolution)\n",
    "    }\n",
    "\n",
    "def run_simulation(data_path, param_file, output_sim_file):\n",
    "    print(f\"\\n=== 阶段 2/3: 模型模拟 ===\")\n",
    "    if not os.path.exists(param_file):\n",
    "        print(\"错误：缺少参数文件，请先运行拟合。\")\n",
    "        return\n",
    "\n",
    "    df_raw = pd.read_csv(data_path)\n",
    "    df_params = pd.read_csv(param_file).set_index('iSub')\n",
    "    sub_ids = df_raw['iSub'].unique()\n",
    "    \n",
    "    all_sim_results = {} # 字典: {sub_id: 模拟结果对象}\n",
    "\n",
    "    print(\"正在生成模拟数据...\")\n",
    "    for sub_id in sub_ids:\n",
    "        if sub_id not in df_params.index: continue\n",
    "        \n",
    "        sub_df = df_raw[df_raw['iSub'] == sub_id].copy().reset_index(drop=True)\n",
    "        params = df_params.loc[sub_id]\n",
    "        \n",
    "        sim_res = simulate_subject(sub_id, sub_df, params)\n",
    "        all_sim_results[sub_id] = sim_res\n",
    "    \n",
    "    # 使用 Pickle 保存所有结果 (因为 cluster_history 是复杂的嵌套列表，CSV存不下)\n",
    "    with open(output_sim_file, 'wb') as f:\n",
    "        pickle.dump(all_sim_results, f)\n",
    "        \n",
    "    print(f\"模拟结束，详细数据已打包保存至: {output_sim_file}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 模块 C: 绘图 (Plotting)\n",
    "# ==========================================\n",
    "\n",
    "def run_plotting(data_path, sim_file):\n",
    "    print(f\"\\n=== 阶段 3/3: 结果绘图 ===\")\n",
    "    if not os.path.exists(sim_file):\n",
    "        print(\"错误：缺少模拟数据文件，请先运行模拟。\")\n",
    "        return\n",
    "\n",
    "    # 1. 加载数据\n",
    "    print(\"正在加载模拟数据...\")\n",
    "    with open(sim_file, 'rb') as f:\n",
    "        all_sim_results = pickle.load(f)\n",
    "    \n",
    "    # 2. 遍历每个被试，绘制个体图表\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "    for sub_id, res in all_sim_results.items():\n",
    "        save_dir = f'plots/iSub_{sub_id}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        trial_df = res['trial_df']\n",
    "        history = res['cluster_history']\n",
    "        trials = trial_df['trial']\n",
    "        \n",
    "        # --- 图 1: Cluster 数量变化 ---\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(trials, trial_df['num_clusters'], 'k-', linewidth=2)\n",
    "        plt.title(f'Subject {sub_id}: Number of Clusters')\n",
    "        plt.xlabel('Trial')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(f'{save_dir}/num_clusters.png')\n",
    "        plt.close()\n",
    "\n",
    "        # --- 图 2: 熵 ---\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(trials, trial_df['entropy'], 'r-', linewidth=1)\n",
    "        plt.title(f'Subject {sub_id}: Prediction Entropy')\n",
    "        plt.xlabel('Trial')\n",
    "        plt.ylabel('Entropy (bits)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(f'{save_dir}/entropy.png')\n",
    "        plt.close()\n",
    "\n",
    "        # --- 图 3: Cluster 均值轨迹 (Dim Evolution) ---\n",
    "        # 需要解析 history 数据\n",
    "        max_clusters = trial_df['num_clusters'].max()\n",
    "        if max_clusters > 0:\n",
    "            vals_per_dim = {d: pd.DataFrame(index=trials, columns=range(max_clusters)) for d in range(4)}\n",
    "            for i, snapshot in enumerate(history):\n",
    "                t_idx = i + 1\n",
    "                for k, mu in enumerate(snapshot):\n",
    "                    for d in range(4):\n",
    "                        vals_per_dim[d].loc[t_idx, k] = mu[d]\n",
    "            \n",
    "            n_cols = 3\n",
    "            n_rows = math.ceil(max_clusters / n_cols)\n",
    "            for d in range(4):\n",
    "                fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows), sharex=True, sharey=True)\n",
    "                fig.suptitle(f'Subject {sub_id} - Feature Dim {d+1}', fontsize=16)\n",
    "                if max_clusters == 1: axes = [axes]\n",
    "                else: axes = axes.flatten()\n",
    "                \n",
    "                for k in range(max_clusters):\n",
    "                    ax = axes[k]\n",
    "                    series = vals_per_dim[d][k].dropna()\n",
    "                    if len(series) > 0:\n",
    "                        ax.plot(series.index, series.values, label=f'C{k+1}', color=f'C{k}')\n",
    "                        ax.set_title(f'Cluster {k+1}')\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'Empty', ha='center', va='center')\n",
    "                    \n",
    "                    if k >= max_clusters - n_cols: ax.set_xlabel('Trial')\n",
    "                \n",
    "                for j in range(max_clusters, len(axes)): axes[j].axis('off')\n",
    "                plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                plt.savefig(f'{save_dir}/dim_{d+1}_clusters.png')\n",
    "                plt.close(fig)\n",
    "\n",
    "    # 3. 绘制总图：Accuracy 对比\n",
    "    print(\"正在生成 Accuracy 汇总图...\")\n",
    "    sub_ids_sorted = sorted(all_sim_results.keys())\n",
    "    n_subs = len(sub_ids_sorted)\n",
    "    n_cols = 5\n",
    "    n_rows = math.ceil(n_subs / n_cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3*n_rows), sharex=True, sharey=True)\n",
    "    fig.suptitle('Model Prob (Correct Category) vs Human Accuracy (Smoothed)', fontsize=16)\n",
    "    \n",
    "    axes_flat = axes.flatten() if n_subs > 1 else [axes]\n",
    "    \n",
    "    for idx, sub_id in enumerate(sub_ids_sorted):\n",
    "        ax = axes_flat[idx]\n",
    "        res = all_sim_results[sub_id]\n",
    "        trial_df = res['trial_df']\n",
    "        \n",
    "        # 数据提取\n",
    "        model_p = trial_df['prob_correct']   # 模型对正确类别的概率 (原始)\n",
    "        human_acc = trial_df['human_correct'] # 被试是否正确 (0/1)\n",
    "        \n",
    "        # 被试数据平滑\n",
    "        human_smooth = human_acc.rolling(window=16, min_periods=1).mean()\n",
    "        \n",
    "        ax.plot(trial_df['trial'], model_p, color='tab:blue', alpha=0.4, linewidth=1, label='Model Prob')\n",
    "        ax.plot(trial_df['trial'], human_smooth, color='tab:red', linewidth=2, label='Human (MA-16)')\n",
    "        \n",
    "        ax.set_title(f'Subject {sub_id}')\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.grid(True, linestyle=':', alpha=0.6)\n",
    "        \n",
    "        if idx == 0: ax.legend(loc='lower right', fontsize='small')\n",
    "        if idx >= n_subs - n_cols: ax.set_xlabel('Trial')\n",
    "        if idx % n_cols == 0: ax.set_ylabel('Acc / Prob')\n",
    "\n",
    "    for j in range(n_subs, len(axes_flat)): axes_flat[j].axis('off')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig('plots/all_subjects_accuracy_comparison.png', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"所有绘图工作完成！\")\n",
    "\n",
    "# ==========================================\n",
    "# 主程序入口\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # ---------------- 开关设置 ----------------\n",
    "    # 设为 True 运行对应步骤，设为 False 跳过\n",
    "    RUN_FITTING    = False   # 1. 拟合参数 (耗时，仅需运行一次)\n",
    "    RUN_SIMULATION = True   # 2. 生成并保存模拟数据 (快，参数改变后需重新运行)\n",
    "    RUN_PLOTTING   = True   # 3. 读取数据并画图 (调整绘图风格时只运行这个)\n",
    "    # ----------------------------------------\n",
    "    \n",
    "    DATA_FILE = 'df_con1.csv'\n",
    "    PARAM_FILE = 'fitted_params.csv'\n",
    "    SIM_FILE = 'simulation_results.pkl' # 保存所有中间结果的二进制文件\n",
    "    \n",
    "    # 1. 拟合\n",
    "    if RUN_FITTING:\n",
    "        if os.path.exists(DATA_FILE):\n",
    "            run_fitting(DATA_FILE, PARAM_FILE)\n",
    "        else:\n",
    "            print(f\"文件不存在: {DATA_FILE}\")\n",
    "\n",
    "    # 2. 模拟\n",
    "    if RUN_SIMULATION:\n",
    "        if os.path.exists(DATA_FILE) and os.path.exists(PARAM_FILE):\n",
    "            run_simulation(DATA_FILE, PARAM_FILE, SIM_FILE)\n",
    "        else:\n",
    "            print(\"无法运行模拟：缺少数据文件或参数文件。\")\n",
    "\n",
    "    # 3. 绘图\n",
    "    if RUN_PLOTTING:\n",
    "        if os.path.exists(SIM_FILE):\n",
    "            run_plotting(DATA_FILE, SIM_FILE)\n",
    "        else:\n",
    "            print(f\"无法运行绘图：缺少模拟结果文件 {SIM_FILE}，请先运行模拟步骤。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653cee74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
